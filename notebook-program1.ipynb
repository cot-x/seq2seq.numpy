{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for comet\n",
    "#from comet_ml import Experiment\n",
    "\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from dataset import ptb\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use gpu.\n"
     ]
    }
   ],
   "source": [
    "#device = 'cpu'\n",
    "device = 'gpu'\n",
    "\n",
    "np = numpy\n",
    "if device == 'gpu':\n",
    "    import cupy\n",
    "    import cupyx\n",
    "    np = cupy\n",
    "print(f'Use {device}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x, ndim=-1):\n",
    "    x = x.astype('float64')\n",
    "    if x.ndim == -1:\n",
    "        ndim = len(x.shape) - 1\n",
    "    c = x.max()\n",
    "    exp_x = np.exp(x - c)\n",
    "    sum_exp_x = np.sum(exp_x, axis=ndim)\n",
    "    out = (exp_x.T / sum_exp_x).T\n",
    "    return out.astype('f')\n",
    "\n",
    "def cross_entropy_error(y, t, onehot=False):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    batch_size = y.shape[0]\n",
    "    if not onehot:\n",
    "        out = -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "    else:\n",
    "        out = -np.sum(np.dot(t, np.log(y + 1e-7))) / batch_size\n",
    "    return out\n",
    "\n",
    "def numerical_diff(f, x, i):\n",
    "    h = 1e-4\n",
    "    h_vec = np.zeros_like(x)\n",
    "    h_vec[i] = h\n",
    "    return (f(x + h_vec) - f(x - h_vec)) / (2*h)\n",
    "\n",
    "def numerical_diff2(f, x, i, j):\n",
    "    h = 1e-4\n",
    "    h_vec = np.zeros_like(x)\n",
    "    h_vec[i, j] = h\n",
    "    return (f(x + h_vec) - f(x - h_vec)) / (2*h)\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    grad = np.zeros_like(x).astype(np.float128)\n",
    "    n, m = x.shape\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            grad[i, j] = numerical_diff2(f, x, i, j)\n",
    "    return grad\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate\n",
    "\n",
    "def to_cpu(x):\n",
    "    if type(x) == numpy.ndarray:\n",
    "        return x\n",
    "    return cupy.asnumpy(x)\n",
    "\n",
    "def to_gpu(x):\n",
    "    if type(x) == cupy.ndarray:\n",
    "        return x\n",
    "    return cupy.array(x)\n",
    "\n",
    "def to_device(x, device=device):\n",
    "    if device == 'gpu':\n",
    "        return to_gpu(x)\n",
    "    else:\n",
    "        return to_cpu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, shape, alpha=0.001, beta1=0.9, beta2=0.999, epsilon=10**(-8)):\n",
    "        self.alpha = alpha\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = np.zeros(shape)\n",
    "        self.v = np.zeros(shape)\n",
    "        self.t = 0\n",
    "\n",
    "    def update(self, w, dw):\n",
    "        self.t += 1\n",
    "        self.m = (self.beta1 * self.m) + (1 - self.beta1) * dw\n",
    "        self.v = (self.beta2 * self.v) + (1 - self.beta2) * dw**2\n",
    "        mh = self.m / (1 - self.beta1 ** self.t)\n",
    "        vh = self.v / (1 - self.beta2 ** self.t)\n",
    "        w -= self.alpha * (mh / (np.sqrt(vh) + self.epsilon))\n",
    "\n",
    "class AdamContainer:\n",
    "    def __init__(self, layers, alpha=0.001, beta1=0.9, beta2=0.999, epsilon=10**(-8)):\n",
    "        self.params = []\n",
    "        for params in [layer.params for layer in layers]:\n",
    "            for param in params:\n",
    "                self.params.append(param)\n",
    "        self.grads = []\n",
    "        for grads in [layer.grads for layer in layers]:\n",
    "            for grad in grads:\n",
    "                self.grads.append(grad)\n",
    "        self.adams = [Adam(param.shape, alpha, beta1, beta2, epsilon) for param in self.params]\n",
    "    \n",
    "    def update(self):\n",
    "        for adam, param, grad in zip(self.adams, self.params, self.grads):\n",
    "            adam.update(param, grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class BaseLayer:\n",
    "    def __init__(self):\n",
    "        self.params = None\n",
    "        self.grads = None\n",
    "        \n",
    "    def to_cpu(self):\n",
    "        for param in self.params:\n",
    "            param = to_cpu(param)\n",
    "        for grad in self.grads:\n",
    "            grad = to_cpu(grad)\n",
    "            \n",
    "    def to_gpu(self):\n",
    "        for param in self.params:\n",
    "            param = to_gpu(param)\n",
    "        for grad in self.grads:\n",
    "            grad = to_gpu(grad)\n",
    "\n",
    "class Affine(BaseLayer):\n",
    "    def __init__(self, w, b):\n",
    "        self.params = [w, b]\n",
    "        self.grads = [np.zeros_like(w), np.zeros_like(b)]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        w, b = self.params\n",
    "        self.x = x\n",
    "        return np.dot(x, w) + b\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        w = self.params[0]\n",
    "        dx = np.dot(dout, w.T)\n",
    "        self.grads[0] = self.dw = np.dot(self.x.T, dout)\n",
    "        self.grads[1] = self.db = np.sum(dout, axis=0)\n",
    "        return dx\n",
    "\n",
    "class TimeAffine(BaseLayer):\n",
    "    def __init__(self, w, b):\n",
    "        self.params = [w, b]\n",
    "        self.grads = [np.zeros_like(w), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        w, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, V = w.shape\n",
    "        \n",
    "        out = np.empty((N, T, V), dtype='f')\n",
    "        self.layers = []\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = Affine(w, b)\n",
    "            out[:,t,:] = layer.forward(xs[:,t,:])\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        self.cache = (N, T, D, V)\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        N, T, D, V = self.cache\n",
    "        \n",
    "        out = np.empty((N, T, D), dtype='f')\n",
    "        dw = np.empty((D, T, V), dtype='f')\n",
    "        db = np.empty((T, V), dtype='f')\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            out[:,t,:] = layer.backward(dout[:,t,:])\n",
    "            dw[:,t,:] = layer.dw\n",
    "            db[t,:] = layer.db\n",
    "        self.grads[0] = self.dw = dw.sum(axis=1)\n",
    "        self.grads[1] = self.db = db.sum(axis=0)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ReLU(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        return dout\n",
    "\n",
    "class Sigmoid(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.out = sigmoid(x)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.out * (1 - self.out)\n",
    "        return dx\n",
    "    \n",
    "class Softmax(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.y = softmax(x)\n",
    "        return self.y\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = self.y * dout\n",
    "        sumdx = np.sum(dx, axis=1, keepdims=True)\n",
    "        dx -= self.y * sumdx\n",
    "        return dx\n",
    "\n",
    "class SoftmaxWithLoss(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1, onehot=False):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if not onehot:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx *= dout\n",
    "            dx = dx / batch_size\n",
    "        else:\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        return dx\n",
    "\n",
    "class TimeSoftmaxWithLoss(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.layers = None\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, xs, ts):\n",
    "        N, T, V = xs.shape\n",
    "        \n",
    "        # if ts is one-hot vector\n",
    "        if ts.ndim == 3:\n",
    "            ts = ts.argmax(axis=2).reshape(N, T)\n",
    "        \n",
    "        ys = np.empty(T, dtype='f')\n",
    "        self.layers = []\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = SoftmaxWithLoss()\n",
    "            ys[t] = layer.forward(xs[:,t,:], ts[:,t])\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        loss = ys.sum() / T\n",
    "        \n",
    "        self.cache = (N, T, V)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self):\n",
    "        N, T, V = self.cache\n",
    "        dx = np.empty((N, T, V), dtype='f')\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            dx[:,t,:] = layer.backward()\n",
    "        self.dx = dx / T\n",
    "        \n",
    "        return self.dx\n",
    "\n",
    "class Dropout(BaseLayer):\n",
    "    def __init__(self, ratio=0.5):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.ratio = ratio\n",
    "        self.mask = None\n",
    "        self.train = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.train:\n",
    "            self.mask = np.random.rand(*x.shape) > self.ratio\n",
    "            self.mask = self.mask.astype('f') / (1.0 - self.ratio)\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask\n",
    "\n",
    "class Embedding(BaseLayer):\n",
    "    def __init__(self, w):\n",
    "        self.params = [w]\n",
    "        self.grads = [np.zeros_like(w)]\n",
    "        self.idx = None\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        w = self.params[0]\n",
    "        self.idx = idx\n",
    "        return w[idx]\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        if device == 'gpu':\n",
    "            add_at = cupyx.scatter_add\n",
    "        else:\n",
    "            add_at = np.add.at\n",
    "            \n",
    "        dw = self.grads[0]\n",
    "        dw[...] = 0\n",
    "        add_at(dw, self.idx, dout)\n",
    "        self.grads[0] = self.dw = dw\n",
    "        return None\n",
    "\n",
    "class TimeEmbedding(BaseLayer):\n",
    "    def __init__(self, w):\n",
    "        self.params = [w]\n",
    "        self.grads = [np.zeros_like(w)]\n",
    "        self.layers = None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        w = self.params[0]\n",
    "        N, T = xs.shape\n",
    "        V, D = w.shape\n",
    "        \n",
    "        out = np.empty((N, T, D), dtype='f')\n",
    "        self.layers = []\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = Embedding(w)\n",
    "            out[:,t,:] = layer.forward(xs[:,t])\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        N, T, D = dout.shape\n",
    "        \n",
    "        dw = 0\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            layer.backward(dout[:,t,:])\n",
    "            dw += layer.dw\n",
    "        self.grads[0] = self.dw = dw\n",
    "        \n",
    "        return None\n",
    "\n",
    "class RNN(BaseLayer):\n",
    "    def __init__(self, wx, wh, b):\n",
    "        self.params = [wx, wh, b]\n",
    "        self.grads = [np.zeros_like(wx), np.zeros_like(wh), np.zeros_like(b)]\n",
    "    \n",
    "    def forward(self, x, h_prev):\n",
    "        wx, wh, b = self.params\n",
    "        t = np.dot(h_prev, wh) + np.dot(x, wx) + b\n",
    "        h_next = np.tanh(t)\n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "    \n",
    "    def backward(self, dh_next):\n",
    "        wx, wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "        \n",
    "        dt = dh_next * (1 - dh_next ** 2)\n",
    "        db = np.sum(dt, axis=0)\n",
    "        dwh = np.dot(h_prev.T, dt)\n",
    "        dh_prev = np.dot(dt, wh.T)\n",
    "        dwx = np.dot(x.T, dt)\n",
    "        dx = np.dot(dt, wx.T)\n",
    "        self.grads[0][...] = self.dwx = dwx\n",
    "        self.grads[1][...] = self.dwh = dwh\n",
    "        self.grads[2][...] = self.db = db\n",
    "        \n",
    "        return dx, dh_prev\n",
    "\n",
    "class TimeRNN(BaseLayer):\n",
    "    def __init__(self, wx, wh, b, stateful=False):\n",
    "        self.params = [wx, wh, b]\n",
    "        self.grads = [np.zeros_like(wx), np.zeros_like(wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        self.h, self.dh = None, None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        wx, wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = wx.shape\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:,t,:], self.h)\n",
    "            hs[:,t,:] = self.h\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        return hs\n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        wx, wh, b  = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = wx.shape\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:,t,:] + dh)\n",
    "            dxs[:,t,:] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "        \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dwx = self.grads[0]\n",
    "        self.dwh = self.grads[1]\n",
    "        self.db = self.grads[2]\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs\n",
    "\n",
    "class LSTM(BaseLayer):\n",
    "    def __init__(self, wx, wh, b):\n",
    "        self.params = [wx, wh, b]\n",
    "        self.grads = [np.zeros_like(wx), np.zeros_like(wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        wx, wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "        \n",
    "        A = np.dot(h_prev, wh) + np.dot(x, wx) + b\n",
    "        \n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "        \n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "        \n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "        \n",
    "        self.cache = (x, h_prev, c_prev,i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "    \n",
    "    def backward(self, dh_next, dc_next):\n",
    "        wx, wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "        \n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "        \n",
    "        dc_prev = ds * f\n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "        \n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= 1 - g ** 2\n",
    "        \n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "        \n",
    "        dwh = np.dot(h_prev.T, dA)\n",
    "        dh_prev = np.dot(dA, wh.T)\n",
    "        dwx = np.dot(x.T, dA)\n",
    "        dx = np.dot(dA, wx.T)\n",
    "        db = dA.sum(axis=0)\n",
    "        \n",
    "        self.grads[0][...] = self.dwx = dwx\n",
    "        self.grads[1][...] = self.dwh = dwh\n",
    "        self.grads[2][...] = self.db = db\n",
    "        \n",
    "        return dx, dh_prev, dc_prev\n",
    "\n",
    "class TimeLSTM(BaseLayer):\n",
    "    def __init__(self, wx, wh, b, stateful=False):\n",
    "        self.params = [wx, wh, b]\n",
    "        self.grads = [np.zeros_like(wx), np.zeros_like(wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        self.h, self.dh, self.c = None, None, None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        wx, wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = wh.shape[0]\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:,t,:], self.h, self.c)\n",
    "            hs[:,t,:] = self.h\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        return hs\n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        wx, wh, b  = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = wx.shape[0]\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:,t,:] + dh, dc)\n",
    "            dxs[:,t,:] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "        \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dwx = self.grads[0]\n",
    "        self.dwh = self.grads[1]\n",
    "        self.db = self.grads[2]\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs\n",
    "\n",
    "class BaseNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = None\n",
    "        self.lastLayer = None\n",
    "        self.adam = None\n",
    "        \n",
    "    def train(self, x, t):\n",
    "        # forward\n",
    "        loss = self.loss(x, t)\n",
    "        \n",
    "        # backward\n",
    "        dout = self.lastLayer.backward()\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "        \n",
    "        self.update()\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def update(self):\n",
    "        for grads in [layer.grads for layer in self.layers.values()]:\n",
    "            clip_grads(grads, self.max_grad)\n",
    "        self.adam.update()\n",
    "    \n",
    "    def save(self, state_file_name = 'network.state.pkl'):\n",
    "        params = self.adam.params.copy()\n",
    "        for i, param in enumerate(params):\n",
    "            params[i] = to_cpu(params[i])\n",
    "            \n",
    "        with open(state_file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "            print(f'Saved: {state_file_name}')\n",
    "            \n",
    "    def load(self, state_file_name = 'network.state.pkl'):\n",
    "        if os.path.exists(state_file_name):\n",
    "            with open(state_file_name, 'rb') as f:\n",
    "                params = pickle.load(f)\n",
    "                for i, param in enumerate(params):\n",
    "                    self.adam.params[i][:] = to_device(param, device)\n",
    "                print(f'Loaded: {state_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(BaseNetwork):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size, max_grad=5.0, dropout_ratio=0.1):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        self.max_grad = max_grad\n",
    "        \n",
    "        embed_w = (rn(V, D) / 100).astype('f')\n",
    "        lstm1_wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm1_wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm1_b = np.zeros(4 * H).astype('f')\n",
    "        lstm2_wx = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm2_wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm2_b = np.zeros(4 * H).astype('f')\n",
    "        ## if use weight tying (require: H == D), comment-out this affine_w\n",
    "        affine_w = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Embedding'] = TimeEmbedding(embed_w)\n",
    "        self.layers['Dropout1'] = Dropout(dropout_ratio)\n",
    "        self.layers['LSTM1'] = TimeLSTM(lstm1_wx, lstm1_wh, lstm1_b, stateful=True)\n",
    "        self.layers['Dropout2'] = Dropout(dropout_ratio)\n",
    "        self.layers['LSTM2'] = TimeLSTM(lstm2_wx, lstm2_wh, lstm2_b, stateful=True)\n",
    "        self.layers['Dropout3'] = Dropout(dropout_ratio)\n",
    "        self.layers['Affine'] = TimeAffine(affine_w, affine_b)\n",
    "        #self.layers['Affine'] = TimeAffine(embed_w.T, affine_b)  # weight tying\n",
    "        self.lastLayer = TimeSoftmaxWithLoss()\n",
    "        \n",
    "        self.lstm_layers = [self.layers['LSTM1'], self.layers['LSTM2']]\n",
    "        self.drop_layers = [self.layers['Dropout1'], self.layers['Dropout2'], self.layers['Dropout3']]\n",
    "        \n",
    "        self.adam = AdamContainer(list(self.layers.values()))\n",
    "        \n",
    "    def predict(self, x, train=False):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train = train\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, t, train=True):\n",
    "        y = self.predict(x, train)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def reset_rnn_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path=None):\n",
    "    if file_path is None or not os.path.exists(file_path):\n",
    "        return ptb.load_data('train')\n",
    "    \n",
    "    words = (open(file_path).read().translate(\n",
    "                str.maketrans({',':'','.':'','-':'',\"'\":'',':':'',';':'','!':'','?':''}))\n",
    "                .lower().strip().split())\n",
    "\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for i, word in enumerate(words):\n",
    "        if word not in word_to_id:\n",
    "            tmp_id = len(word_to_id)\n",
    "            word_to_id[word] = tmp_id\n",
    "            id_to_word[tmp_id] = word\n",
    "            \n",
    "    corpus = np.array([word_to_id[w] for w in words])\n",
    "\n",
    "    return corpus, word_to_id, id_to_word\n",
    "\n",
    "def make_corpus(str):\n",
    "    corpus = []\n",
    "    word_to_id = {}\n",
    "    id_to_word = {}\n",
    "    for word in str.lower().strip().split():\n",
    "        if word not in word_to_id:\n",
    "            tmp_id = len(word_to_id)\n",
    "            word_to_id[word] = tmp_id\n",
    "            id_to_word[tmp_id] = word\n",
    "        corpus.append(word_to_id[word])\n",
    "    return corpus, word_to_id, id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y):\n",
    "    x = x / np.sqrt(np.sum(x ** 2))\n",
    "    y = y / np.sqrt(np.sum(y ** 2))\n",
    "    return np.dot(x, y)\n",
    "\n",
    "def most_similar(word_to_id, id_to_word, word_matrix, queries=['you', 'say', 'good'], top=5):\n",
    "    for query in queries:\n",
    "        if query not in word_to_id:\n",
    "            print(f'{query} is not found.')\n",
    "            continue\n",
    "\n",
    "        print(f'\\n{query}')\n",
    "        query_id = word_to_id[query]\n",
    "        query_vec = word_matrix[query_id]\n",
    "\n",
    "        vocab_size = len(word_matrix)\n",
    "        similarity = np.zeros(vocab_size)\n",
    "        for i in range(vocab_size):\n",
    "            similarity[i] = cos_similarity(word_matrix[i], query_vec)\n",
    "\n",
    "        count = 0\n",
    "        for i in (-1 * similarity).argsort():\n",
    "            if id_to_word[i.item()] == query:\n",
    "                continue\n",
    "            print(f' {id_to_word[i.item()]}: {similarity[i.item()]}')\n",
    "            count += 1\n",
    "            if count >= top:\n",
    "                break\n",
    "\n",
    "def generate_seq(network, start_id, sample_size=100):\n",
    "    word_ids = [start_id]\n",
    "    \n",
    "    x = start_id\n",
    "    while len(word_ids) < sample_size:\n",
    "        x = np.array(x).reshape(1,1)\n",
    "        score = network.predict(x)\n",
    "        p = softmax(score.flatten())\n",
    "        x = np.random.choice(len(p), size=1, p=p)\n",
    "        word_ids.append(x.item())\n",
    "        \n",
    "    return word_ids\n",
    "\n",
    "def print_generate_seq(network, word_to_id, id_to_word, start_word='you', load_state=True):\n",
    "    start_id = word_to_id[start_word]\n",
    "    network.reset_rnn_state()\n",
    "    word_ids = generate_seq(network, start_id)\n",
    "    network.reset_rnn_state()\n",
    "    txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "    txt = txt.replace('<eos>', '.\\n')\n",
    "    print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Program1:\n",
    "    def __init__(self):\n",
    "        self.params = OrderedDict({'batch_size': 64, 'corpus_size': 202646,\n",
    "                                  'wordvec_size': 512, 'hidden_size': 512,\n",
    "                                  'time_size': 32, 'max_epoch': 100})\n",
    "        self.losses = []\n",
    "        self.ppl_list = []\n",
    "        \n",
    "    def __call__(self):\n",
    "        ## for comet\n",
    "        #experiment = Experiment()\n",
    "        #experiment.log_parameters(self.params)\n",
    "        \n",
    "        corpus, word_to_id, id_to_word = load_data('dataset/tinyshakespare.txt')\n",
    "        #corpus, word_to_id, id_to_word = load_data()\n",
    "        print(f'max_corpus_size: {len(corpus)}')\n",
    "        corpus = corpus[:self.params['corpus_size']]\n",
    "        self.params['corpus_size'] = len(corpus)\n",
    "        vocab_size = int(max(corpus) + 1)\n",
    "        self.params['vocab_size'] = vocab_size\n",
    "        \n",
    "        self.corpus = corpus\n",
    "        self.word_to_id = word_to_id\n",
    "        self.id_to_word = id_to_word\n",
    "        \n",
    "        xs = corpus[:-1]\n",
    "        ts = corpus[1:]\n",
    "        data_size = len(xs)\n",
    "        \n",
    "        for key in self.params.keys() :\n",
    "            print(f'{key}: {self.params[key]}')\n",
    "        batch_size, corpus_size, wordvec_size, hidden_size, time_size, max_epoch, vocab_size = self.params.values()\n",
    "\n",
    "        self.net = Network(vocab_size, wordvec_size, hidden_size)\n",
    "        self.net.load()\n",
    "        \n",
    "        print()\n",
    "        print_generate_seq(self.net, word_to_id, id_to_word)\n",
    "        print()\n",
    "        most_similar(word_to_id, id_to_word, self.net.layers['Embedding'].params[0])\n",
    "        print()\n",
    "        \n",
    "        max_iters = data_size // (batch_size * time_size)\n",
    "        time_idx = 0\n",
    "        total_loss = 0\n",
    "        loss_count = 0\n",
    "        \n",
    "        jump = (corpus_size - 1) // batch_size\n",
    "        offsets = [i * jump for i in range(batch_size)]\n",
    "        \n",
    "        for epoch in range(max_epoch):\n",
    "            for ite in tqdm(range(max_iters)):\n",
    "                batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "                batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        \n",
    "                for t in range(time_size):\n",
    "                    for i, offset in enumerate(offsets):\n",
    "                        batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                        batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "                    time_idx += 1\n",
    "                \n",
    "                loss = self.net.train(batch_x, batch_t)\n",
    "                self.losses.append(loss.tolist())\n",
    "                total_loss += loss\n",
    "                loss_count += 1\n",
    "                \n",
    "                ## for comet\n",
    "                #experiment.log_metric('loss', loss, step=epoch*max_iters-(max_iters-ite))\n",
    "            \n",
    "            ppl = float(np.exp(total_loss / loss_count))\n",
    "            print(f'| epoch {epoch+1} | total_loss {total_loss} | perplexity {ppl}')\n",
    "            self.ppl_list.append(ppl)\n",
    "            if len(self.ppl_list) > 1 and min(self.ppl_list[:-1]) >= ppl:\n",
    "                self.net.save(f'network.state.ppl_min.pkl')\n",
    "            \n",
    "            time_idx, total_loss, loss_count = 0, 0, 0\n",
    "            \n",
    "            ## for comet\n",
    "            #experiment.log_metric('perplexity', ppl, step=epoch*max_iters)\n",
    "        \n",
    "        print()\n",
    "        print_generate_seq(self.net, word_to_id, id_to_word)\n",
    "        print()\n",
    "        most_similar(word_to_id, id_to_word, self.net.layers['Embedding'].params[0])\n",
    "        \n",
    "        self.net.save()\n",
    "\n",
    "        ## for comet\n",
    "        #experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_corpus_size: 202646\n",
      "batch_size: 64\n",
      "corpus_size: 202646\n",
      "wordvec_size: 512\n",
      "hidden_size: 512\n",
      "time_size: 32\n",
      "max_epoch: 100\n",
      "vocab_size: 12848\n",
      "\n",
      "you severals sacrifices taskd woodville christophero shilling sands perverse betid flourishd tuners medler peaces stored treasury staring prayed integrity falconbridge taste agenor fiddlestick trifling pardond grief mercutio betrothd put doubted distressd joint wagoner arrested satisfy dreaded holier digest jacob between signet fares drugs fatherinlaw lieutenant cannons dallied answer therefore song outdares signories kentishmen holdinganchor bespice speech paltering iv mammet mean complete herd food twangling hurdle wrung condemn dependency shrouds bagot enfoldings hearkens losses coursers nicely leicestershire gibingly forms unfurnish fellowships open wonderd said ages flatter urgent upstaringthen dog handed sparkling blusters already deed if forges tiger looking debts forego digressing\n",
      "\n",
      "\n",
      "you\n",
      " conferring: 0.1741846203804016\n",
      " play: 0.17240743339061737\n",
      " plausible: 0.14684318006038666\n",
      " pelting: 0.1463770717382431\n",
      " robert: 0.14430968463420868\n",
      "\n",
      "say\n",
      " chances: 0.19400814175605774\n",
      " ithere: 0.17486344277858734\n",
      " xanthippe: 0.16837891936302185\n",
      " boast: 0.16375279426574707\n",
      " anna: 0.1627153754234314\n",
      "\n",
      "good\n",
      " tickle: 0.16180355846881866\n",
      " sung: 0.1558316946029663\n",
      " desirers: 0.15550801157951355\n",
      " awakes: 0.14598330855369568\n",
      " ely: 0.14296071231365204\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:23<00:00,  4.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | total_loss 848.32958984375 | perplexity 5746.94970703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:24<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 2 | total_loss 841.87255859375 | perplexity 5380.49755859375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:25<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 3 | total_loss 841.6493530273438 | perplexity 5368.25830078125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:26<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 4 | total_loss 841.0814208984375 | perplexity 5337.236328125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:26<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 5 | total_loss 839.991943359375 | perplexity 5278.2314453125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:27<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 6 | total_loss 839.78369140625 | perplexity 5267.02783203125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 7 | total_loss 839.4341430664062 | perplexity 5248.275390625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 8 | total_loss 838.4376220703125 | perplexity 5195.17578125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 9 | total_loss 837.173828125 | perplexity 5128.61083984375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:29<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 10 | total_loss 835.77734375 | perplexity 5056.04736328125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:35<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 11 | total_loss 834.5205688476562 | perplexity 4991.62255859375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 12 | total_loss 833.416748046875 | perplexity 4935.712890625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:32<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 13 | total_loss 832.3846435546875 | perplexity 4884.005859375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:29<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 14 | total_loss 831.3765869140625 | perplexity 4834.02490234375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:31<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 15 | total_loss 830.368896484375 | perplexity 4784.5732421875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:27<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 16 | total_loss 829.2969970703125 | perplexity 4732.5263671875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:35<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 17 | total_loss 828.4402465820312 | perplexity 4691.33349609375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 18 | total_loss 827.7034912109375 | perplexity 4656.197265625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 19 | total_loss 826.9309692382812 | perplexity 4619.63623046875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 20 | total_loss 826.23388671875 | perplexity 4586.8916015625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 21 | total_loss 825.58642578125 | perplexity 4556.689453125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:29<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 22 | total_loss 824.8977661132812 | perplexity 4524.779296875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 23 | total_loss 824.4203491210938 | perplexity 4502.791015625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 24 | total_loss 823.8753051757812 | perplexity 4477.81689453125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:31<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 25 | total_loss 823.3408813476562 | perplexity 4453.46533203125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:33<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 26 | total_loss 822.9443969726562 | perplexity 4435.4853515625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:29<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 27 | total_loss 822.4093627929688 | perplexity 4411.333984375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 28 | total_loss 821.9672241210938 | perplexity 4391.4755859375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 29 | total_loss 821.6908569335938 | perplexity 4379.109375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 30 | total_loss 821.40234375 | perplexity 4366.236328125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:29<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 31 | total_loss 821.0428466796875 | perplexity 4350.2470703125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:26<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 32 | total_loss 820.6280517578125 | perplexity 4331.87353515625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 33 | total_loss 820.3253173828125 | perplexity 4318.513671875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:34<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 34 | total_loss 819.912841796875 | perplexity 4300.376953125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 35 | total_loss 819.5875854492188 | perplexity 4286.12451171875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 36 | total_loss 819.207763671875 | perplexity 4269.544921875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 37 | total_loss 818.9916381835938 | perplexity 4260.14111328125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:31<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 38 | total_loss 818.6702880859375 | perplexity 4246.19580078125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 39 | total_loss 818.3541870117188 | perplexity 4232.5185546875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:31<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 40 | total_loss 818.0499877929688 | perplexity 4219.40478515625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 41 | total_loss 817.6658325195312 | perplexity 4202.89453125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 42 | total_loss 817.3495483398438 | perplexity 4189.35302734375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 43 | total_loss 817.1996459960938 | perplexity 4182.94921875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 44 | total_loss 816.684814453125 | perplexity 4161.0341796875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:29<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 45 | total_loss 816.3857421875 | perplexity 4148.35498046875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:31<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 46 | total_loss 816.0047607421875 | perplexity 4132.25732421875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:31<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 47 | total_loss 815.6754150390625 | perplexity 4118.39306640625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 48 | total_loss 815.4068603515625 | perplexity 4107.12451171875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 49 | total_loss 815.2159423828125 | perplexity 4099.13037109375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:29<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 50 | total_loss 814.89453125 | perplexity 4085.708740234375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 51 | total_loss 814.6229858398438 | perplexity 4074.401123046875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 52 | total_loss 814.46533203125 | perplexity 4067.855224609375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 53 | total_loss 814.02978515625 | perplexity 4049.813232421875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 54 | total_loss 813.8841552734375 | perplexity 4043.800537109375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:32<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 55 | total_loss 813.52197265625 | perplexity 4028.884033203125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:33<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 56 | total_loss 813.225341796875 | perplexity 4016.707275390625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:33<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 57 | total_loss 812.9697265625 | perplexity 4006.244140625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:36<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 58 | total_loss 812.6646728515625 | perplexity 3993.79296875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:33<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 59 | total_loss 812.3152465820312 | perplexity 3979.577392578125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:29<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 60 | total_loss 811.9488525390625 | perplexity 3964.72802734375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:33<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 61 | total_loss 811.6358032226562 | perplexity 3952.08154296875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:31<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 62 | total_loss 811.41455078125 | perplexity 3943.170654296875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 63 | total_loss 811.0205688476562 | perplexity 3927.347900390625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:32<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 64 | total_loss 810.9473266601562 | perplexity 3924.416259765625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:31<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 65 | total_loss 810.8486938476562 | perplexity 3920.466064453125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 66 | total_loss 810.8196411132812 | perplexity 3919.3076171875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:27<00:00,  3.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 67 | total_loss 810.2654418945312 | perplexity 3897.205078125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:31<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 68 | total_loss 809.8743286132812 | perplexity 3881.681884765625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:32<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 69 | total_loss 809.6228637695312 | perplexity 3871.73291015625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:31<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 70 | total_loss 809.3762817382812 | perplexity 3862.0048828125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:32<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 71 | total_loss 809.0885620117188 | perplexity 3850.68115234375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:27<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 72 | total_loss 808.8681030273438 | perplexity 3842.031494140625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 73 | total_loss 808.4144287109375 | perplexity 3824.28369140625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 74 | total_loss 808.3956298828125 | perplexity 3823.550537109375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:31<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 75 | total_loss 807.84716796875 | perplexity 3802.213134765625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 76 | total_loss 807.572998046875 | perplexity 3791.589111328125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 77 | total_loss 807.4171142578125 | perplexity 3785.5625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 78 | total_loss 807.1741943359375 | perplexity 3776.191162109375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 79 | total_loss 807.0513305664062 | perplexity 3771.462158203125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:33<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 80 | total_loss 806.67431640625 | perplexity 3756.98095703125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:34<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 81 | total_loss 806.2242431640625 | perplexity 3739.76513671875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:29<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 82 | total_loss 805.83203125 | perplexity 3724.826171875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 83 | total_loss 805.4759521484375 | perplexity 3711.316650390625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:31<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 84 | total_loss 805.3406372070312 | perplexity 3706.19873046875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:29<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 85 | total_loss 805.260986328125 | perplexity 3703.18505859375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:29<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 86 | total_loss 805.0859375 | perplexity 3696.576171875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 87 | total_loss 804.8408203125 | perplexity 3687.34423828125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:31<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 88 | total_loss 804.3069458007812 | perplexity 3667.30908203125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 89 | total_loss 803.99609375 | perplexity 3655.695068359375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:35<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 90 | total_loss 803.5044555664062 | perplexity 3637.40283203125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:26<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 91 | total_loss 803.2274780273438 | perplexity 3627.135498046875\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:32<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 92 | total_loss 802.8145141601562 | perplexity 3611.885009765625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:32<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 93 | total_loss 802.9190673828125 | perplexity 3615.73828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:29<00:00,  3.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 94 | total_loss 802.5658569335938 | perplexity 3602.73095703125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:28<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 95 | total_loss 802.396728515625 | perplexity 3596.517333984375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:31<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 96 | total_loss 802.2410888671875 | perplexity 3590.81103515625\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:27<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 97 | total_loss 801.7984619140625 | perplexity 3574.62939453125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:30<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 98 | total_loss 801.4974365234375 | perplexity 3563.665771484375\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:32<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 99 | total_loss 801.09326171875 | perplexity 3549.00048828125\n",
      "Saved: network.state.ppl_min.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 98/98 [00:29<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 100 | total_loss 800.6895751953125 | perplexity 3534.409423828125\n",
      "Saved: network.state.ppl_min.pkl\n",
      "\n",
      "you unbid temperately quarry personally mankind pirates boiled paly vowed dreams hotly hold usurpers vienna to northampton religious flourisheth and loosebodied scholar fight yesterday shewolf preserver distribution unmannerd sit mean girls waitingvassals quiet smell afterdinners plumepluckd tears worm wedlock waits wards cedar slanderous purchased wherewith gasp broil and consumed plays morecast looker cleaving peevish lamenting belongings mandrakes logs fellows burns perverse the scouts of renew for joyless expectst cursing twisted boil sweethearts lass transport courtodor loves rudiments lethargy merchandise illgot comforted vent discase unpeopled allies ledas sap closure thoughts least forewarnd horse guard audience sessions escapes uneasy about george rule\n",
      "\n",
      "\n",
      "you\n",
      " conferring: 0.1741846203804016\n",
      " play: 0.17240743339061737\n",
      " plausible: 0.14684318006038666\n",
      " pelting: 0.1463770717382431\n",
      " robert: 0.14430968463420868\n",
      "\n",
      "say\n",
      " chances: 0.19400814175605774\n",
      " ithere: 0.17486344277858734\n",
      " xanthippe: 0.16837891936302185\n",
      " boast: 0.16375279426574707\n",
      " anna: 0.1627153754234314\n",
      "\n",
      "good\n",
      " tickle: 0.16180355846881866\n",
      " sung: 0.1558316946029663\n",
      " desirers: 0.15550801157951355\n",
      " awakes: 0.14598330855369568\n",
      " ely: 0.14296071231365204\n",
      "Saved: network.state.pkl\n"
     ]
    }
   ],
   "source": [
    "program = Program1()\n",
    "if __name__ == '__main__':\n",
    "    program()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABZl0lEQVR4nO3deVxU5f4H8M+wOKDCKCoCioIr5p5moqi5dzWzbuVWYppdu2pqi6ll5hppZqYtVr9y17ymlqWpuIeSiizuuwIiiBszCLLO+f0xzMDsMzDAGc/n/Xpxr3PmOWeeOdrMl+/zfZ5HJgiCACIiIiIRc6nsDhARERFZw4CFiIiIRI8BCxEREYkeAxYiIiISPQYsREREJHoMWIiIiEj0GLAQERGR6DFgISIiItFzq+wO2EKtVuPWrVvw8vKCTCar7O4QERGRDQRBQGZmJgICAuDiUrYciVMELLdu3UJgYGBld4OIiIhKITk5GfXr1y/TNZwiYPHy8gKgecPe3t6V3BsiIiKyhUqlQmBgoO57vCycImDRDgN5e3szYCEiInIyjijnYNEtERERiR4DFiIiIhI9BixEREQkegxYiIiISPQYsBAREZHoMWAhIiIi0WPAQkRERKLHgIWIiIhEjwELERERiR4DFiIiIhI9BixEREQkegxYiIiISPScYvPD8rI19ibikjIwqG0AOgX7VHZ3iIiIyAxJZ1gOXLyDtf8k4tTNjMruChEREVkg6YClVrUqAID7WXmV3BMiIiKyRNIBi2cVVwBATr66kntCRERElkg6YHF3kQEACtUMWIiIiMRM0gGLTKYJWNRCJXeEiIiILJJ0wOJSFLAUCoxYiIiIxEzSAYtr0bsXGLAQERGJmqQDFt2QEEtYiIiIRE3iAYvm/9XMsBAREYmatAMWaCIWhitERETiZnfAkpmZiSlTpqBhw4bw9PREly5dcOLECZvOPXLkCNzc3NCuXTt7X7ZcaDMsREREJG52Byxjx45FZGQk1q5di9OnT6Nfv37o06cPUlJSLJ6nVCoRHh6O3r17l7qz5YUjQkREROJmV8Dy6NEjbNmyBYsWLUL37t3RpEkTzJ49G8HBwfjuu+8snjtu3DiMGDECoaGhZeqwIzHBQkRE5BzsClgKCgpQWFgIDw8PveOenp6Iiooye97KlStx9epVfPLJJza9Tm5uLlQqld5PeRJYxUJERCRqdgUsXl5eCA0Nxbx583Dr1i0UFhZi3bp1OHbsGFJTU02ec/nyZUyfPh3r16+Hm5ubTa8TEREBhUKh+wkMDLSnmzZjDQsREZFzsLuGZe3atRAEAfXq1YNcLseyZcswYsQIuLq6GrUtLCzEiBEjMGfOHDRr1szm15gxYwaUSqXuJzk52d5u2ocJFiIiIlGzLeVRQuPGjXHo0CFkZWVBpVLB398fQ4cORXBwsFHbzMxMxMTEIC4uDhMnTgQAqNVqCIIANzc37NmzB7169TI6Ty6XQy6Xl+Lt2EfGKhYiIiKnYHfAolWtWjVUq1YNDx48wO7du7Fo0SKjNt7e3jh9+rTesW+//Rb79+/Hr7/+ajLIqQxMsBAREYmb3QHL7t27IQgCmjdvjitXrmDq1Klo3rw5Ro8eDUAznJOSkoI1a9bAxcUFrVq10jvf19cXHh4eRscrA2tYiIiInIPdNSxKpRITJkxASEgIwsPDERYWhj179sDd3R0AkJqaiqSkJId3tDxx80MiIiJxkwlO8G2tUqmgUCigVCrh7e3tsOv+39/XMH/HeQxuF4CvhrV32HWJiIjIsd/f0t5LiGNCRERETkHSAYuW+HNMRERE0ibpgIX5FSIiIucg6YBFiwkWIiIicZN0wMISFiIiIucg6YBFywkmShEREUmapAMWJliIiIicg6QDFi3mV4iIiMRN0gEL12EhIiJyDpIOWHSYYiEiIhI1SQcs2gSLwIiFiIhI1KQdsFR2B4iIiMgmkg5YtDirmYiISNykHbCw6JaIiMgpSDtgKcIMCxERkbhJOmBhfoWIiMg5SDpg0eIsISIiInGTdMDCEhYiIiLnIOmARYs1LEREROIm6YBFxioWIiIipyDpgEWLCRYiIiJxk3TAoluanxELERGRqEk7YKnsDhAREZFNJB2wFGOKhYiISMwkHbBwWjMREZFzkHTAosUaFiIiInGTdMDCac1ERETOQdIBixYTLEREROIm7YCFCRYiIiKnIO2ApYjAIhYiIiJRk3TAwgQLERGRc5B0wKLF/AoREZG4STpgkRUtxMIRISIiInGTdsBS2R0gIiIim0g6YNFigoWIiEjcJB2wcGl+IiIi52B3wJKZmYkpU6agYcOG8PT0RJcuXXDixAmz7bdu3Yq+ffuiTp068Pb2RmhoKHbv3l2mTjsapzUTERGJm90By9ixYxEZGYm1a9fi9OnT6NevH/r06YOUlBST7Q8fPoy+ffti586dOHnyJHr27IlBgwYhLi6uzJ0vK2ZYiIiInINMsCO98OjRI3h5eeH333/HwIEDdcfbtWuH5557DvPnz7fpOi1btsTQoUMxa9Ysm9qrVCooFAoolUp4e3vb2l2rtsXdxDubEtCtaW2sfeNph12XiIiIHPv97WZP44KCAhQWFsLDw0PvuKenJ6Kiomy6hlqtRmZmJnx8fMy2yc3NRW5uru6xSqWyp5s24+aHREREzsGuISEvLy+EhoZi3rx5uHXrFgoLC7Fu3TocO3YMqampNl3jiy++QFZWFoYMGWK2TUREBBQKhe4nMDDQnm7ajSUsRERE4mZ3DcvatWshCALq1asHuVyOZcuWYcSIEXB1dbV67saNGzF79mxs2rQJvr6+ZtvNmDEDSqVS95OcnGxvN23CGhYiIiLnYNeQEAA0btwYhw4dQlZWFlQqFfz9/TF06FAEBwdbPG/Tpk144403sHnzZvTp08diW7lcDrlcbm/XSk3gSixERESiVup1WKpVqwZ/f388ePAAu3fvxuDBg8223bhxI15//XVs2LBBr1hXLDgkREREJG52Z1h2794NQRDQvHlzXLlyBVOnTkXz5s0xevRoAJrhnJSUFKxZswaAJlgJDw/HV199hc6dOyMtLQ2AplBXoVA48K3YT8YxISIiIqdgd4ZFqVRiwoQJCAkJQXh4OMLCwrBnzx64u7sDAFJTU5GUlKRr//3336OgoAATJkyAv7+/7mfy5MmOexdlxAwLERGRuNmdYRkyZIjFGT6rVq3Se3zw4EF7X6LCML9CRETkHCS9l5AWi26JiIjETdIBC0tYiIiInIOkAxYt1rAQERGJm6QDFi7NT0RE5BwkHbBoMcFCREQkbpIOWFjDQkRE5BwkHbDoMMVCREQkapIOWLQJFk5rJiIiEjdpBywcEiIiInIKkg5YtDitmYiISNwkHrAwxUJEROQMJB6waDDBQkREJG6SDlhYw0JEROQcJB2waAksYiEiIhI1SQcsTLAQERE5B0kHLFrMrxAREYmbpAMWGYtYiIiInIKkAxYtlrAQERGJm6QDluKl+YmIiEjMpB2wcESIiIjIKUg6YNHhmBAREZGoSTpgYYaFiIjIOUg6YNFifoWIiEjcJB2wyLh0HBERkVOQdMCixRIWIiIicZN2wMIECxERkVOQdsBSRGAVCxERkahJOmBhgoWIiMg5SDpg0WINCxERkbhJOmDRbn7IgIWIiEjcpB2wVHYHiIiIyCaSDli0mGAhIiISN0kHLFyan4iIyDlIOmDREljEQkREJGqSDli4ND8REZFzkHTAQkRERM7B7oAlMzMTU6ZMQcOGDeHp6YkuXbrgxIkTFs85dOgQOnToAA8PDzRq1AgrVqwodYcdiTUsREREzsHugGXs2LGIjIzE2rVrcfr0afTr1w99+vRBSkqKyfbXr1/HgAED0K1bN8TFxeHDDz/EpEmTsGXLljJ33lFYwkJERCRudgUsjx49wpYtW7Bo0SJ0794dTZo0wezZsxEcHIzvvvvO5DkrVqxAgwYNsHTpUrRo0QJjx47FmDFjsHjxYoe8gbJggoWIiMg52BWwFBQUoLCwEB4eHnrHPT09ERUVZfKc6Oho9OvXT+9Y//79ERMTg/z8fJPn5ObmQqVS6f2UJ25+SEREJG52BSxeXl4IDQ3FvHnzcOvWLRQWFmLdunU4duwYUlNTTZ6TlpaGunXr6h2rW7cuCgoKcPfuXZPnREREQKFQ6H4CAwPt6abtilIsHBIiIiISN7trWNauXQtBEFCvXj3I5XIsW7YMI0aMgKurq9lzZAbVrdp1TwyPa82YMQNKpVL3k5ycbG83bcJpzURERM7Bzd4TGjdujEOHDiErKwsqlQr+/v4YOnQogoODTbb38/NDWlqa3rH09HS4ubmhVq1aJs+Ry+WQy+X2dq3UmGAhIiISt1Kvw1KtWjX4+/vjwYMH2L17NwYPHmyyXWhoKCIjI/WO7dmzBx07doS7u3tpX94hOK2ZiIjIOdgdsOzevRu7du3C9evXERkZiZ49e6J58+YYPXo0AM1wTnh4uK79W2+9hcTERLz77rs4f/48fv75Z/z00094//33HfcuyohL8xMREYmb3QGLUqnEhAkTEBISgvDwcISFhWHPnj26bElqaiqSkpJ07YODg7Fz504cPHgQ7dq1w7x587Bs2TK89NJLjnsXpcQECxERkXOQCU6QXlCpVFAoFFAqlfD29nbYdY9du4ehP/yDRnWqYf97zzjsukREROTY729J7yVkbpYSERERiYukAxYd0eeYiIiIpE3SAQsTLERERM5B0gGLFhMsRERE4ibpgEWbYHGCumMiIiJJk3bAwiEhIiIipyDpgEWL+RUiIiJxk3jAwhQLERGRM5B4wKLBEhYiIiJxk3TAwhoWIiIi5yDpgEVLYBULERGRqEk6YGGChYiIyDlIOmDRYg0LERGRuEk6YOHmh0RERM5B0gGLFjMsRERE4ibpgIX5FSIiIucg7YCFEQsREZFTkHTAosXND4mIiMRN0gGLjINCRERETkHSAYsW8ytERETiJumAhTUsREREzkHSAYsWS1iIiIjEjQELERERiR4DFnDzQyIiIrGTdMDCGhYiIiLnIOmARYs1LEREROIm6YBFuw4L4xUiIiJxk3bAwiEhIiIipyDpgEWLQ0JERETiJumAhRkWIiIi5yDpgKUYUyxERERiJumAhZsfEhEROQdJByxarGEhIiISN0kHLKxhISIicg6SDli0mGAhIiISN0kHLEywEBEROQe7ApaCggLMnDkTwcHB8PT0RKNGjTB37lyo1WqL561fvx5t27ZF1apV4e/vj9GjR+PevXtl6rgjCSxiISIiEjW7ApaFCxdixYoV+Prrr3H+/HksWrQIn3/+OZYvX272nKioKISHh+ONN97A2bNnsXnzZpw4cQJjx44tc+fLSlvDwnCFiIhI3NzsaRwdHY3Bgwdj4MCBAICgoCBs3LgRMTExZs/5559/EBQUhEmTJgEAgoODMW7cOCxatKgM3XYUDgoRERE5A7syLGFhYdi3bx8uXboEAEhISEBUVBQGDBhg9pwuXbrg5s2b2LlzJwRBwO3bt/Hrr7/qgh5TcnNzoVKp9H7KE0eEiIiIxM2uDMu0adOgVCoREhICV1dXFBYWYsGCBRg+fLjZc7p06YL169dj6NChyMnJQUFBAZ5//nmLw0gRERGYM2eOPV0rFU5rJiIicg52ZVg2bdqEdevWYcOGDYiNjcXq1auxePFirF692uw5586dw6RJkzBr1iycPHkSu3btwvXr1/HWW2+ZPWfGjBlQKpW6n+TkZHu6aTcW3RIREYmbTLDj2zowMBDTp0/HhAkTdMfmz5+PdevW4cKFCybPGTlyJHJycrB582bdsaioKHTr1g23bt2Cv7+/1ddVqVRQKBRQKpXw9va2tbtWXbvzEL2+OARvDzecmt3fYdclIiIix35/25Vhyc7OhouL/imurq4WpzWbOwcQT2ZDHL0gIiIic+wKWAYNGoQFCxZgx44duHHjBrZt24YlS5bgxRdf1LWZMWMGwsPD9c7ZunUrvvvuO1y7dg1HjhzBpEmT0KlTJwQEBDjunZSCjEUsRERETsGuotvly5fj448/xvjx45Geno6AgACMGzcOs2bN0rVJTU1FUlKS7vHrr7+OzMxMfP3113jvvfdQo0YN9OrVCwsXLnTcuygrpliIiIhEza4alspSXjUsN+5m4ZnFB+Eld8PpOaxhISIicqRKq2F5XIk+YiMiIpI4SQcsuqX5xZ9kIiIikjRpByxcmp+IiMgpSDpg0WJ+hYiISNwkHbBwVjMREZFzkHTAosUSFiIiInFjwEJERESix4AFgMAqFiIiIlGTdMDCGhYiIiLnIOmARYs1LEREROIm6YCFmx8SERE5B0kHLFpMsBAREYmbpAMWXX6FEQsREZGoSTtg4YgQERGRU5B0wKLFac1ERETiJumApeTmh2o1gxYiIiKxknTAopVfKKDd3D34ev9l3bETN+7jh8NXGcgQERGJgKQDlpI1LKqcAizec0n3+JUV0fh05wXsOJ1q9vyVR65jyPfReJhbUJ7dJCIikjxJByy2uHYnCwCQpsxB0PQdCJq+A4VFWZc5f5zD8ev3sTLquq69wFXoiIiIHE7SAYupSULpmTl6j1U5+QCARbsu6I61mLVLr012fiEAIFX5CKER+7F832VYcvNBNnILCkvRYyIiImmSdMBiyphVJ/Qe/xR1HYVqAbkFat2xvBJ/Lmlp5GWkqXLwReQlk88DwMnEBwhbeACDvz7imA4TERFJgLQDFhMpljMpKqNj8ckPLF5m//l0AEChDcNB2+JuAgAupGXa0EEiIiICpB6w2EgQLK/VcvF2Jq7fzeImikREROVE0gGLzGQVS+ncfJCt9/jYtXsAgB8OX8W/vvobGdl5RuecTNRkbm7czULEX+ex7/xth/WHiIjocSLtgMVMvGI40+fXkzex83SaXdcb+sM/AIBPd17A+VQV2s2NhCAIelmYId9HAwCeWXwQ3x+6hjdWx+DsLaV9b4KIiEgCJB2wmPPdoat6j385kWzTedaGhI5fv683sFRoYlG6K+kPbXotIiIiKZF0wGJuQGjRrotWz137T6Ldr6d8lG/3OURERCTxgKUsPv7tjNExW3Z/tqUw935WHp5asBdNP9rJjAsREREkHrDIbIkw7GAYjAwtqlHRPV/ify35/vBV3MnMRX6hgD5LDjmsf0RERM5K0gFLeTt2/b7RMVsyLIWFxo2U2fmIuXGfS/8TEZEkSTpgcWx+xXFMhST9lh7Cyyuisfus9dlKREREjxtJByyOdOLGA2yJvWmxjSAIFnd/tuS2KhcA8MPha6U6n4iIyJlJOmBxZAnLMisbHgLAW+tikZlTUKbXiU3KwPW7WWW6BhERkbORdMDirI5f16yiG3X5Lkb+dAxHrtyt5B4RERGVL7fK7kBlcuTS/KX17NLDRsfyC03vBl3SycQHeO2nYwCAvy/fxY3PBjq8b0RERGJhV4aloKAAM2fORHBwMDw9PdGoUSPMnTsXarXlL9jc3Fx89NFHaNiwIeRyORo3boyff/65TB13iMqPV4x2bZ6/4zzWRFtflO7gxfTy6hIREZHo2JVhWbhwIVasWIHVq1ejZcuWiImJwejRo6FQKDB58mSz5w0ZMgS3b9/GTz/9hCZNmiA9PR0FBWWr5Xhc3cnMLdP5D3MLcP9hHhrUquqgHhEREVU+uwKW6OhoDB48GAMHaoYfgoKCsHHjRsTExJg9Z9euXTh06BCuXbsGHx8f3Xli4OB14ypdSsYjdP1sPwBg77s90MS3eiX3iIiIyDHsGhIKCwvDvn37cOnSJQBAQkICoqKiMGDAALPnbN++HR07dsSiRYtQr149NGvWDO+//z4ePXpk9pzc3FyoVCq9H7Ku28L9uj9HXb5TiT0hIiJyLLsyLNOmTYNSqURISAhcXV1RWFiIBQsWYPjw4WbPuXbtGqKiouDh4YFt27bh7t27GD9+PO7fv2+2jiUiIgJz5syx752UwmOWYIGJzZ8BADn5hfBwd63YzhARETmQXRmWTZs2Yd26ddiwYQNiY2OxevVqLF68GKtXrzZ7jlqthkwmw/r169GpUycMGDAAS5YswapVq8xmWWbMmAGlUqn7SU5Otu9d2cjRewmVl73nbpf63L8v30HIx7sw54+zDuwRERFRxbIrYJk6dSqmT5+OYcOGoXXr1hg5ciTeeecdREREmD3H398f9erVg0Kh0B1r0aIFBEHAzZumV4aVy+Xw9vbW+ykPbi7OEbCMXWO+RsgcbbJl5E/HAQArj9wAAPwen4KXvzuK26ocB/WOiIio/NkVsGRnZ8PFRf8UV1dXi9Oau3btilu3buHhw4e6Y5cuXYKLiwvq169vZ3cdy1kCFkO7z97G8v1XrLZLVRpnsCb/Eo+YxAd4+tN9yM7jTC0iInIOdgUsgwYNwoIFC7Bjxw7cuHED27Ztw5IlS/Diiy/q2syYMQPh4eG6xyNGjECtWrUwevRonDt3DocPH8bUqVMxZswYeHp6Ou6dlIKrkwYs+y8Yr8Hy4bbTRse2xqZYvM7G45qhtt/jU9Dj8wO4+SAbAKBWC2WeXk1ERORIdgUsy5cvx8svv4zx48ejRYsWeP/99zFu3DjMmzdP1yY1NRVJSUm6x9WrV0dkZCQyMjLQsWNHvPrqqxg0aBCWLVvmuHdRSs5Sw2KLDceS9B5n5xUiLinD4jl5BZrM2ORf4pF4LxthCw8AAKZsisdTC/ZycToiIhINu2YJeXl5YenSpVi6dKnZNqtWrTI6FhISgsjISHv7RmXw+e6LNrVLN1HLsj3hFgDg9ZUncGp2P3h7uDu0b0RERPbi5ocS98epVIvPry4q1i1UC/gtLgXJ97MroFdERET6GLBInCCYWbylSH7R4i6bTiRjyqZ4dFt0QPfcsWv3sHzfZRSaWwCGiIjIQSS9WzPZzrCod8Whq/jsrwsAgNpecgztGIj3Nifg1M0MfPtqBzT386qMbhIR0WOKGRYJ0dam2Cv66j2jY9pgBQCu383C/gvp2BaXgqt3stB/6eFS95GIiMgUZlgkZNLGOL3Hj/IKcDQ5w+p51+9mWW3zMJdruhARUflhhkXClu2/gr8v37XaTkDpalR+PXkTQdN3YOrmBIt1LtbqaIiIiBiwkJ57D40XjCttPPH+5gQAwOaTN/G/mOL9oNKUOcgv1KwBs+lEEp6cF4l4GzI9REQkXQxYSE+H+Xv1HtuytJ4tbS6kqqBWC+i75BA6R+zDi98eAQBM23IaD7Lz8fbGWPs7S0REksEaFrLoTIoSBy/dcci1jly9i8vpD4uuq9J7Lvn+IwiCYPPqwxE7zyOghidGdQlySN+IiEjcmGEx8EzzOpXdBVHZdyHdqP6koND8ZpeWZOUWWn6t86a3AsjIzsP2hFu6RevO3lLi+8PX8Mn2s6XqBxEROR8GLCWcnt0PXw1tr3v85dC2RhskVnF1wVNBNSu6a6LSvcTicVqlLcwtac+5NBSqBbz83VEETd+BX45r9kd67adjmLQxDt0WHcA/1+5ZDXyIiOjxw4ClBC+DPXO6NK6Nq58O0Dt2bm5//Pz6UxXZLdG5pTTef8gRBAE4dv0eYhIfAACmb9UsVldy+Gi9wSaP2g0c/758B0/Oi8Ts7Wd1Bb1ERPT4YMBigalqCjdXF706i2nPhqB7M2kPI526qcQ7mxJsaGk9C1NQaF+m5rnlfwMARv50HPez8rDq6A38HHVd9/zD3AKouXUAEZHTY8BSCiUDmWdb+WHNmE6V1hcxiL5mvBJuadhYb6vn0u2HRsdO3NBkaG5lPEKrT3Zj6A/RZe2antyCQkRfvafL7hARUfljwGLAlloMa1+sz7b0w+JX2jqoR84pO09/5duMR/nYcDzZTOtijsyF/FG0FYE2gDFna+xNnLqZYfN1Z2w9jeE//sOiXyKiCsSAxRIzgYmsxBOmmqwY2QHPtfEvnz45iSdm7dZ7/Hv8LRx20PRoWzIxgiAgosR+R+YcvXoX7/4vAc9/fcTm198amwIA2Hg8yUpLIiJyFAYsNvCS6y9XY8sXZsk2a8Z0wsY3O6OKW/Ht/uDZ5vjfuFBHddEpnUlRGh2zdmttHTU6n5ppdOzAhXSERuzD2ugbEAQBgiBgxI/H9Nqo1QIu3c7U2y7gSnomrt0xHnrSEgQBb609if+uO2lj74iIyF6SXzjux/COePd/8fhySDsA0CuodSn688b/dMb8Hecw7dkQo/PNBS8lszC1q8vxRIC33vPjn2lS6vVMHhfPLY8q1Xm2bBVgaqbQ6FUnAAAf/34WXh7uaFNfYdRm9h9nsSY6EW3rK7B1fFfk5BeizxLN7tOTejXBu/2aG51zPysPu86mAQAeZOWhZrUq9rwdIiKygeQDlr5P1EXCrH5wKVpvReHpjlc61Ida0AQaANCqngK//Me+bEjJQEb3Z8GwTSmqTB9jCclK7DydZrGNWhAsZju0rMU0v568aRREAsCa6ERNX24qseroDfR7oq7uuWX7r5gMWDgJiYio/HFICNAFK1qfv9IWXwyxrWhWZmaQwtRRw4Lekm0m9WqCIR3rw9Pd1abXfRxdvJ2Jh7kFFtv8eSpVtz5Ledt5OtVqm+ir+jOk8tXFmR3DwmMAWH30BvZfuG1XPwoK1UbDVEREUsOApRRKJkZcXc0ELCUamR02KnG8R3NfLHq5LTyrSDdgMSXBhl2cTyZangVUWrYECPP+PKf3uM8XhwBodqF+YtZudP1sPzJz8gEAu86k4ZPtZzFmVYyu/V0Tu2Mben9zAvp9eRg/Fa0v8+G20xi7OoYBDBFJCgOWUpC7ueL1LkEY0rE+6tXwBAD4esn12sj0/mx7UMMvIX2Dv7E+e+el744aHaus+6jK0WRVpm3RZIFSMh5h3p/nUFCoxlsGRbmrjlxHx/l7sWzfZd2xyHO38Xt8iu7xg6w8/BavmZ797cGrAIANx5Kw9/xt/HHKegaIiOhxwYCllGY/3xKLXi4eNlrzRid0bVILW8d3AWA6q6LwdDc+aMGy4e2tNyIjgiDgssGCcoaZGkfsfWSrmBsPkGNikbnZf2iyM0siL+FOZi7UagFvronB5F/icSdTk3mZsine7HUnbYyzqx+5BdyDiYicFwMWBwnx88b6sZ3xZAPNxoglsycBNTwAAKtGd0ILf2+TK+Oaqst9vm0A9r/Xo7y6/NjadyEdH2w5pXfMMFMjCMZ1Ro/y9L/QK7KY9oNfE/T+7uOLAqxDNqxdk1egxrcHr2Dc2hjdjtaCIOhtSXDwYjqaz9yFoOk7cOl28ZTvB1l5UD7Kd8h7ICIqTwxYytHxD3vj7w966jZVbFVPgb8mdzO595A2wDEcyWhUp3q591OKTI0YtZi1S++xI5fetzYf7EKaflHtm2tiTLYzNdS1aNcFLNp1EbvP3sb49bEANFO4G324E+PXa4ah3v1f8V5Pr/98HACw8sh1tJ8XibZz9pjdb0kQBG4mSUSiwIClHPl6eyDQp2pld4NMECAg8V62xTamhvXWRN8o5etZZ0tGx1SgVXIH6yvpmqGwgxc1mRlT08S1u23P+aO4YLhQEJCRnYdFuy7gSnpxBmbEj8fQYV4ksqzM3iqpUC3gyJW7UOUwc0NEjsOARSSCa1UDwKLbivLPtfsYayaLoaUWgJjE+3rHZv2uv3+QtWnYgCYYsIUtdTXl+a/jo9/O4NuDV3UL5QGajS1VOQU4cuWu7lhGdh42HEuCMtt0QLLq6A28+n/HMPT7f3TH4pIeYMvJm+XXeSJ67El+4bjKFjOzDx7lFUJRVTNsZOkLaVyPRrj/MA9/nUmz6YuSyuZ8qgrvbEqw2CavQI0DF9MttrmbmWs1EJXBthV8yzOgjU/K0P15e8ItPN82QPf47Y1xuDj/XwCACRticeTKPfx1JhVr33gaAJB0LxsCBDSsVQ3b4jSByflUle78F7/VzOQK9KmKTsE+dvVLEAQuskhEzLBUttrV5frDRha+j7o3rYPPX2mL6nLGmWKRpsrBB7+estjGxUVmNTOiFmwMWGzvmh57v+4NZyDlFqihyslHemYOjlzRLJb392VN1iU+OQPdPz+AHp8fRE6+fuGy4X5R1++aX6U4+X620UJ8R6/eRbu5kdhetPM2EUkXAxaRebpRLQBA7erG+9Ho1mqpwCm5ZL8JRYWvWqayJ4aZkjRVjtW/V82GjY7oYel9uPWM0bEXSszAyswp0Ovjvw3WyNGuSSQIAk4mPtCrjem26ACG//iP3hT0UT8fh/JRvtkp3NrnrGW5iMj5MWARmc9fboN3+jTDtvFdjZ4ztQBdnxa+FdEtssMOgyX9VTkFCC+amaPVe8kho/PyCyxHIw+y88stWLU1A2MpQ2KK4UyrD7acgiAI2HQiGS99dxQtP9lttIVBws0MAJpp5vmFlt/v4t0XsT3hFkavPKE79sPhq3j5u6N2FQoTkfgxYBGZmtWqYHKfpjbPLvpkUEuE+HnpHo/r3qi8ukZlYLhw3bU7WUZt2s7do/f4fKrKaKaSYYZFrRZMtLE/qHFkGGSt3OTmg0fYEltcgDv5l3i957VTrJfvvwxrUotmPJX06c4LiEl8gLX/aDayLFQL2BZ3E0lWZoURkbgxYHECDWtpgpc29RVGzwX6VMWuKd11j58K8sGK156ssL5R+dl0ItkoQJlmsCDe9oRbem0e5RdW+rCRvSLP6W8GOfsPzVYGpw3qXwAg6vJdvPjtkRIzjsy/WW09zS8nkvDOpgR0//yAw/pMRBWP1ZtOYN+7PZBfKOg2RrT0hSSTAc+28kejOtVM/hZPzmPV0RtGx36P1y8+NZx2DRh/hVfkVHmZzLbiYWuu3TX9b/e1n44BAOKSMtAp2Mfia2lX8DUs5AU0Bb4X0jLRp4UvZDIZ8gvV+P7QVYQ1rYN2gTUAAL+evIkdp25h+YgnWehOJALMsDgBN1cXvV2cLX0fcPan9Bj+nasNvsVNfak/Y5BtsDXIqMjpxdZe635WnsX/FlYeuWG07YA269Jt0QG8uSYGH27TbFK5JjoRi/dcwgvfHNG1eX9zAg5cvIPvD121q98FXBmYqFwwYHnM6ApzS3yS73uvB07N7lc5HaJytetMGrIN9kAyDD4iz982CmpulLKeoyKzNfa+1mET+y5p6oCK3/x/1urvmL3xeDKu3nmIi2nFa8a8sfqEXhtVUdBz72Euen1xEN8cuKJ77n8xyRj+wz+6RfRuq3LQbm4kPioKhIjIcewKWAoKCjBz5kwEBwfD09MTjRo1wty5c6FW2/YbxZEjR+Dm5oZ27dqVpq9kh5If9Y3rVIe3h307RZNzuPswz+hYs5l/6T2eujnBZLuSlI/ykZLxqMz9qcwEn+FMLK2SgY+poCbpvn7wpl1nxvD5bw9exbU7Wfh890Xdcx/8egrR1+5hWVGB8M9HruNhboHedgm2OHAhHRM2xJpdPZiI7AxYFi5ciBUrVuDrr7/G+fPnsWjRInz++edYvny51XOVSiXCw8PRu3fvUneWNAa10axA2sLfW3esdnU5AOh2i7Zk3uCW5dMxEiVVjvXpvU8t2Gu1TYGVKcZA+W4dYPL1KiDjc+DiHaRkPNLbBNJwpWmVhR2voy7fxYfbTlucZj161QnsOJWKz/dcKHuHiR5TdlWSRUdHY/DgwRg4cCAAICgoCBs3bkRMjOU9WQBg3LhxGDFiBFxdXfHbb7+VqrOk8cGzzdG+QQ2ENamtO3Zkek/k5Kuh8Cxa4t/CB7m3pztWjX4Kr688YbYNkaEn50VabbM11nH7BYlpOf5TyRl6Q22v/vgPfp8YZtO52kJhhac7pj0bgoJCNeb+eQ5dGtfGs6389NqmKXN1fy4oVMPNtfh3yk0nkvBT1HX8NOopbqpKkmRXhiUsLAz79u3DpUuXAAAJCQmIiorCgAEDLJ63cuVKXL16FZ988olNr5ObmwuVSqX3Q8U83F0xqG0AalYrXg1X7uaqC1YAa4W5MjzT3BctA7wttCKpC5q+w+5ztpxMMTr27cEreo9TlTkOm3pdWTO4E27qT7nefPKm0S8JtwyG2E4VLYi3+eRNrIlOxFvrTuK2yngdGUBTUNxubiSm/FK8wu+0Ladx6fZDzPmjeAPO5PvZRtmeRyVqmgrVAqZuTsD6Y4m2vzkikbIrYJk2bRqGDx+OkJAQuLu7o3379pgyZQqGDx9u9pzLly9j+vTpWL9+PdzcbEvoREREQKFQ6H4CAwPt6SbBytTniusGSYyppMiiXRf1Hs/8zbggdcZW/WP/O5FcqtcqT9ZWGf7nmv4U835fHtZ7fOTKPdx8kI20EovdGbbZe/421GoBm2OS8TC3AL/FG++hlJOvGZq6duchui06gM6f7tM99+nO82gxaxdibmj6EnnuNjafvImPthlvqWDJ5phkdP50H87d4i+LJB52BSybNm3CunXrsGHDBsTGxmL16tVYvHgxVq9ebbJ9YWEhRowYgTlz5qBZs2Y2v86MGTOgVCp1P8nJ1j+8SN+CF1sBAN7ra/6+lwxqRnZuiC+HttU9ntizSbn1jR4fhlmYC2mZOGvlS+62Khc3H+hnHzYe1y9SXWliDRpTHJWpMbXthb1SlY/0Uj6mdlQ/ZFD0azjtGgB2n02zGIxFXbkLtVpA1JW7Rq/zw+FrAICFuzS1MJZqayyZ+usppKly8M6meN2x/8Uk40jRaxJVBrtqWKZOnYrp06dj2LBhAIDWrVsjMTERERERGDVqlFH7zMxMxMTEIC4uDhMnTgQAqNVqCIIANzc37NmzB7169TI6Ty6XQy6Xl+b9UJFuTevgwrxn4eHuavScqQ/DeS9oApx3NiUAAAJ9PDGlT1Ms3Wt9eXQieygf5Zv8ojZkSwjhZIv6ArDeZ8PtBn48fA1vGmy5YW33akcEYABQUDQD9EyKUrcr+Y3PBjrk2kT2sivDkp2dDRcX/VNcXV3NTmv29vbG6dOnER8fr/t566230Lx5c8THx+Ppp58ufc/JKlPBSknWPjin9GmGp4KszzoicrRCtWCUjbifZTw1O7sCNzh02IQkOy+0YOd5o2MpGY/KFJLkFhTaNY3dsB7HFLVawH/WxOCzv4pnOu09dxv9vzzMoSVyCLsyLIMGDcKCBQvQoEEDtGzZEnFxcViyZAnGjBmjazNjxgykpKRgzZo1cHFxQatWrfSu4evrCw8PD6PjVHG0v31ZmklU3KZCukRkleEspU93nkdM4gO9Y3vOpuk9PpOiNNox2hSH7YJdSQViV9Iz0cS3eBNUS/0oVAt4cm4ksvIKsX1iV7QKUOCDLacQUMMTk3s3hauL8cnmZmyp1QJcitqfuHEfe87dBnAb0/8VAgAYu0Yzg/StdSdx+IOepXtzREXsCliWL1+Ojz/+GOPHj0d6ejoCAgIwbtw4zJo1S9cmNTUVSUn2LZpEImS8YC6RqBgWuQLGK9nO32GcnTBk6qv4tMEsIMBx/y3Ych2bhnRKBBF9lhzWG6o5fv0+BEEwGYhN3BCLrKKZRNvjb+Huw1z8WrSZ5MnE+1g/trOu7dU7WZodwU28/C/Hk7Bg53msHtMJTzaoiTwLWxKYquchspddQ0JeXl5YunQpEhMT8ejRI1y9ehXz589HlSrF02tXrVqFgwcPmr3G7NmzER8fX9r+kgOIaHkLogpnarq2YYAw6OsovccPcwtsyzaKKMI/eNF4VV8A+OuMfhYqs8TCgoar/ALG9TLajNX0raeRmVOAietj7eqXWi3oZXdv3M3Cwl0XcPdhroWzNFsjkLRxLyEJ0n402zL1ueQHy553uiNmZp9y6xdRZZix9TQ2xVieiTj111M4d8s461KSqV8E1Gr7I5jkB8b7PGk3ZLRHbJL+cJm5IWBrC/SduKGfyRr8zRG9x7eUOTZv+JhfqMa/vvobb64pXmz0xW+P4LuDV3UzktRqAcN/+AeTS6xB82XkJXSYvxfr/uF6MlLGgEVCqss1I4AdigppB7T2BwAE165m0/nN6nrptgAAgE8GPYFdU7ohtFEtB/eUqOIYzsoxx3CxOEPxSRlGx/INJiTIILOaqVl55IZRtsGWWVWG0lX613h/8ym7r2HK+VTjAlrDaenmJCRn4OLtTOw9n6479qBo/6SYG5oA60JaJqKv3cPvJdag+WqfZrbizN/sW0+GHi921bCQczvxUR9k5RXogo7xPRujuV91dAo2H3BY+mx1d3VBiJ83h5iIAKyOtv7bv6makuw84/qO74vWU7HE2n92m2KS8WTDGrrHW2Jv4oshbc2fYOm1rLxYXFIGgmz4xafkdd7fnIDFrxj3R23D2JsgCPjvulh4ebjhcxPXsCS/UA13V/6u7oz4tyYhnlVc9TIk7q4ueLaVP3xKLPGvpU0Tl2aWUMNa3OeEHn+2bLxouGLvR9vO4PvDV/WOzfvTemGwqSEhR/2iYMv7sOW1Sl7GsN7E1AJ22kJfe14DAFQ5+Ui8l41dZ9Ow+eRNi8NR+YVqvee3J9xC04/+wh9W1rEhcWLAQibZ81lY8oPq9Ox+2PtuD4f3h0hsbClP+fj3s0bH8g12vbZlOKXH5wdt7ZaeCluWwOAD4+kS2wUAQIFaQJxBTU1pLfzrAgpLvLGSNTglp7AXqgWELdyPZxYf1NUSTdqoqYt5e2OcXevQkDgwYCGLLG+iaHzMy8Od6VaShH5fHqq0105IzrBpfyDDepP/GRQX77+Y7phdsQ0+KApMRHM//m15mCs7rxDZedZnY12989Bkm//FJKPZzL/w5ylN9uS2Kke3DUS2iQzV9C2lr+nJzivA7/EppaototLjNwuZFFxHMx7dq7kvAJgeNirlKlk1q7qbLNQ1sV4VkWhdvZNVaa+tWaDNOsO6Gu3y+lrXbHwPhv+tn0mxXIBcWrYMjxnSFihr39vEDXG4cdf6+7qTaXqa9OXbmXjhmyOYvf2s2dlZ07ecxuRf4vHfdSdNPk/lgwEL6dk2vguWDm2HJxtoZhL995nG+HJoW/w1uVuprvef7o3w2b9bo2uT4gDlxEd9sOHN4m0ZJvduivhZfTGwTYDV68nd+E+WqDxlZBtvgWDIqCbF5l829Bsa1s8YDo/F3DBeHNCQ4fATYLz7922V5ZlgBy6m67YPGP7jMcQnZ2DV0Ru6TSQFQcCcP85ibfQNAMVr0xy9arxujb0EQcBNE1PZyRg//UlP+wY18UL7errHVdxc8GL7+qjr7VGq6/l6yTGsUwPI3Yr3NXJzdTFKQ9eoapzBMRT3cV+8WKJvRFSs5NomZXHdIDux/liS9YDExBDNozzra8f8fdny7s8vr4i2/QVLyM4v1Buy7v2F+eG7tdE3MHrlCQxY9jcA6E0pP3BBM/36v+tisfLIDZM1SWU178/zCFt4AD9HXXf4tR83DFio0mk/WEr+tvVa5waYUbQfCQCM7NwQNatV4d5GRGZE2jhMZEhbiKr15hrHDHNEX9MPRkxlI0quslsZcvILrQYheQVq7DLYo8oWmTn5WPdPotGaOvHJGbiSngkAyMotwM9HNIFKyU0jbXHjbhaS7+tnZmwJEp0ZAxay27CnAlG/pieeb6cZwrFl4zibNloscWz+C60xrkdj3eOqclej19r4ZmccmvqMHT0nImusLZFvigDNFGJLMrJLV6BqWGsiCI6Z/ZRfqLbpC77QxtWK5/95Du9vTtB91s3YehozfzuD8J+O69rcyczFC98cQZ8lhwEAn2wvXcYmK7cAzyw+iG6LDuj6t/5YIlrM2mU0XfxxwoXjyG6fvdQGgiDYNLtAt56LxTbWX9PU7tGhjbnCLlFF2Hkq1eLz2+JSsC0uRe/YX6etZyVM/bJjeOzQpTsGz1tnS0mNrdkda7+Q7T13G71b+OL/ioZ0MrLz8H+jntLt2XSuxEwtw1qV3SX2ddK+jionHzn5hfD1Kh6GP5OixPL9l/HBsyFoXKc6jl0vzlYVqNVwdXHVzRp7f3MCXu5Q36b35myYYaFSKRmsvPSk5j+OJ/y9jdsV/b+zbRxHRMU2G/zWnmvD3kGG55hSiq2WcPy69UJcoPSzGO310W+n9d6HdtuBklll7Z9tuSdtZu9BpwX79Iqfn/86CrvP3sbrKzXZmjGrbKtXWrDjHCL+sn/mlVgxYKEye7lDfWwb3wW//jfU6Lm2gQoAwJCOgQCAVvXMBzWWcPl/IvEYvfKEQ65jWD8D2PbLjWGT0qyHYtPqvbb2x0qjn4/cAABsOGZ+kUDDAOtCWqbuz9qAKPm+7Yvd3c/Kw49/X8f3h64hM0dzf+KTMzB9yymjwmpnwSEhKjOZTIb2RdOgtQ5NfQY37mWjQ0MfAMCA1n74a3I3kxst6opuLaRYdJkaC/0YFdoQb3ZvhB8PX7NpXxciqli27BN0IU1/sbv3NycYtYk2KODdbsNS+4Y7Z9tam2LNbVWuyc+lkse+2nsJb4QFGzcqEaOY+/y7WCJwMcdUwFYyKFGrNUNXY4tmkh26dAfRM3pbva7YMMNC5aJhrWro0ayO7rFMJkMLf294uLtaOMs6S593MpkM9WtWtXtkqa63HK88pmO+RGLyitlpysWmbTlttY1hsarh3kXxyRlGGZSdZ/TrcO4+NF5vxpY9kEwpdRGwhfMidmqGcsavtz5ra46J4t2Xvjuq91i7pgxg+w7lYsOAhSqdLRst2lSYa6LN4HYBeL1LkO7xyx3qY8ekMLzZrfi3nWMf9rF7x1ciEo+ley8bHTP8PEmz4Ut6vcGQzYPsfJt+ATJZPFzGBE7CTc1qwspH1ouDYxJLt0/TycQH2BrrPLOKOCRElU67eq3FgEU39dmWKdTFf/5qWHsAwKqjNwAAbi4ytAxQYHs8d2slepwZflbkmSgUzi3QP2ZqmMiWYSxrTVQ2zEgy3BSzxNUtnieDzPovdGae12Zhqsvd0K+ln5WLVD5mWKjSTO3fHO0b1MCIpxsAAHqGaIaQPEsMG2n/QwxrWlvzBxuCGltY+ghoGeCNlzvUx7+5qi6R0zIMIhbtumjUpnOE/rL+X+0zztQYZmZMrTdj+FoFJtvoN8otcMwib7b8EmetyX/WnjS7b5KYMMNClWZCzyaY0LOJ7vErHQLhU02ONvUVumPHP+yDpPtZuuJdW5R1IbsmvtWx+JW2+DLyktk29Wp4oolvdXh7uuOPooK/Hs3qIL9Q7ZD9RYiobCZuiHXIdfp9eVjvccRO4xVpDT9zfjmRbNzG4CPn56gbVl/b2uwjW22Nsz7sk5GdDz9F2WoMyxszLCQaLi4y9H2irt6+RXW85HrBSpkXoLNpkTrrr9UywBurx3RCy4Diadqrx3TChjc7W38BIip3sUkZ5XJd7VL6JRnGFVfvPDRuY/A48V6W1TUd4pMzrA432RLT2DKLyhkwYCGn0sS3utGxBj5VAQAD2/gDsPYfsPUCX1M+fbE1Fr7Uuvgquv2PzJ/TKcgH/xfeEVP7N7fvxYjIqdjycZJXYH2xPcOMysojNxy2su/jsJYVh4TIqbwRFoys3AL0buGrO7Z7SnfcVuUgyMQaL4Zsy8IYN9LW2RhOubQ0/CR3d0GfJ+oimVvHEz3WDAtz/zCR0Wgxa5fV6xj+ApRwMwP3s4ynXxuytk3KYxCrAGDAQk7Gw90VHzwbonfMs4qrXrDisF0AbNiw0RJT07Un9GyMrNxC3awlW9Ss6o5nmvvC10uO7w9fs/k8IqoYi3frF/SaWuPF0MGLd4z2M5qxVf8XosR7FffLjqOKgMsTh4RIUkztd2TIlhqW0praPwSzn29psc3rXYIwqG2A7nH9mlXx5dB2eCLAet+JqOKtKcXK2mkq43VhNsUYF+vawhEZFFMzpMSGGRZ67JhKjPz5dhiOXb+P4Z0amG2j1aVJbatt7CnetSRA4YHQxrXh7emGlUX7jWgDGm1a2ZZ6GSKShqDpO/Qer41OxLVS7A100mCxudhSLj5XkZhhocfOkI6aZfbbBdbQHWtVT4E3woLh6qL59m/uZ1y8e2R6L3z76pMW11/pFKSZsfTq0w0B2BbUWIozAn2q4oshbdGsrpeFVtrrmL9SA5+q+HpEe73CYEN1veVYNfopfDPiSauvRUTOYcHO0u3GbLh0vzNghoUeO+0b1MQ/M3qjVvUqZtu83CEQykf56BRcS3esXg1P1KvhqXtsKkBY/+bTuK3KQf2aVW3uj6W1FOyaZl3iMt2a1satjEe4ekfzm5XczQXPtQnALoP9Ukpyc3HBM819cfBiui3dJqLHiD0La4oVMyz0WPJTeMDd1fw/b1cXGf7TvbFeFsbQ8201mZYQv+Lsh7uri83BSpfGmmCoQ8OaZtvIbJlmbSKqWTOmEyLf6WFTPyxZ8GIrjOlqYhdZInJaQ0xsMnnxtvVdn8WOGRYiM5r7eeH4h71Rs5r5TI0pf3/QE9HX7uHFoqGl9g1q4pf/dEagj+1ZmZJM/V4kk+nvH2JLnYupISrt0JapxbCIyDkdv3Ff7/HFNOcPVgAGLEQW+ZZYdddWgT5VjYKTzo1qmWxbx0sOwLahIds2h7TQxobXqOLmgkm9msDXywMfbDll/QQiEr2sPPFPWbYFh4SIyuDVpxvAX+GB17sE2XXeT6M6oleILz5+7gkAwPNtAxBcuxpGdm5o1Fa7t5K9k4T+/WQ9tDU15GXhQt4ebpjYqyka1ipdNoiIqLwww0JUBjWqVsHR6b2srjRpqHeLuujdoq7ucTW5G/a/10PvOrumdMOOU6kY16MxAM3migDQuI7xir6mXn7JkHYAjKdB2rQ5pNUWREQViwELURnZG6zYep0QP2+E+BUvFlfHS45Ts/uhqrvxjqqeVVz1/t/k9YuGjdoHaoqAveSm/vM3LgL+ZNATOHdLhc0ni3d8faZ5HXRsWBOL92h2tF49phMu387E/B36Uyz9FR5IVRovkEVE4uKoz7HyxCEhIifi7eEOtxKzn74a1g7N6lbH5y+3BQD0aFoHL7QLwIx/hZi7BGpWq4K4j/vixMw+Rs+Z+swa3TUYn7/SVve4utwNq0Z3QremdXTHujetjbHdGukeu7rIsO+9Hvi/UR3ten9EROYww0LkxAa3q4fB7YoXunNxkWHpsPYm25YMRqzNfLI0bGRu1pKhxnWq49JjMJWSSAqul2K13IpmV4aloKAAM2fORHBwMDw9PdGoUSPMnTsXarX5bbO3bt2Kvn37ok6dOvD29kZoaCh2795d5o4TkX1aBSisttGGHdVNDhcZNLLhOiWHlva91wNrxnTSa/f9yA7YNr6L1ev5lWK2FhHZJydf3LOJ7MqwLFy4ECtWrMDq1avRsmVLxMTEYPTo0VAoFJg8ebLJcw4fPoy+ffvi008/RY0aNbBy5UoMGjQIx44dQ/v2pn8TJCLH+WtyN/x68iYm9mxita02UdK6ngKvdwmyuHaMvYW5jWpXQ+M6+lsi9G/ph+T7xTvSbvpPZyTey9abUv3X5G7w8nBD2MIDAIC5g1vibIqq1BvFEZFpYi9jsStgiY6OxuDBgzFw4EAAQFBQEDZu3IiYmBiz5yxdulTv8aefforff/8df/zxBwMWogrQwt9bN33aHG8PN6hyCvB00VYFMpnM7K7SVYpqaGzZcqDk0JItRX1tA2vg6Ua19AKWFv7euJOZq3v8XJsAhIcGMWAhcjCxL99v15BQWFgY9u3bh0uXNDMDEhISEBUVhQEDBth8DbVajczMTPj4+Jhtk5ubC5VKpfdDROXnz7e74f1+zTDvhVZm23wz4kn4KzzwY1Ehrb/C02xbreDa1VCtiisCFOaHdCwtiOdi4vPT1Edqt6a1EfFv8xs/mjL/hVb47zON7TqHiCqPXRmWadOmQalUIiQkBK6urigsLMSCBQswfPhwm6/xxRdfICsrC0OGDDHbJiIiAnPmzLGna0RUBg1qVcXEXk0tthnYxh8D2/jrHvspPLBmTCd4eRh/jCg8NUW9cjdXxM7qC1c7c80b3+yMOX+cxYIXNQGUtbVj1r7xNLJyCzBj62kAwLbxXZBboMawH/7RayeTFQdIoY1roXGd6lhx6KrlvZyIJMKWNZoqk10Zlk2bNmHdunXYsGEDYmNjsXr1aixevBirV6+26fyNGzdi9uzZ2LRpE3x9fc22mzFjBpRKpe4nOZmpXyIx6t6sDto3KN7cce0bndCqnjdWjX5Kd0zu5qo3FXvE0w0AAJN6ma+pCW1cC7umdEeHhsaZWHOxT8mPWl9vD6PtEFaOfgpHpvUqvo72vBInvtAuAMuHWx6qXjOmE/6Z0dtiGyJyPLsyLFOnTsX06dMxbNgwAEDr1q2RmJiIiIgIjBo1yuK5mzZtwhtvvIHNmzejTx/j9R9KksvlkMvl9nSNiESgW9M6euuzmDJvcCuEhzZE87qaXbADfTzRKcgH1eSukLuZ+R3Khl/8StbUmIppejb3RX6h+RmNALB0WHsUWGnTvZnl90fkrCxM+BUFuzIs2dnZcHHRP8XV1dXitGZAk1l5/fXXsWHDBl3BLhFJk6uLDCF+3roiXJlMhk3jOmPl6E5mC3PlbsUr+Lq7Wv/YMpeFcXORoX2DGmjqWx0NaxlvcWAoPLQhujQ2vXGlJe0b1LC4eB+RGH3213nrjSqRXRmWQYMGYcGCBWjQoAFatmyJuLg4LFmyBGPGjNG1mTFjBlJSUrBmzRoAmmAlPDwcX331FTp37oy0tDQAgKenJxQK6+tCENHjz9oMIkVVd3wy6Am4yGSoVrRGzLgejfD9oWsY172RxXMNX2frf7tAEDSL7Fnry5COgWhVT4EWH+/CIzvWqNg2visAIOKvCzafQ1TZTqUoK7sLFtmVYVm+fDlefvlljB8/Hi1atMD777+PcePGYd68ebo2qampSEpK0j3+/vvvUVBQgAkTJsDf31/3Y27dFiIiU0Z3DcaoErtiT382BJHvdMe0Z81nMvyLZid5uBd/1MlkMr1gZVSoZofs/i01m1GaCmMsFSN+++qT+DG8I2pUdbflbdhl3uCW2PLfUIdfl8gUF5EvxGJXhsXLywtLly41WlulpFWrVuk9PnjwYCm6RURkmUwmQ9OiOhhAszpv7xBf5BWqdSvjrn2jE77YcwlvW5gB9dHAJ9Dnibp4Ksh8ga+lWUR1veXo0NDH7hUs5jzfEq3rK/Dvb4+abTMyNMjOq5r261uhqOvtgW6LDjjkevR4MpN0FA3uJUREjwWZTIafXn9K71gTXy9891oHi+dVcXPRKxQ29UvmB8+GYN6f5zCyc0Oz17FUW/Ptq0+irrccb2+Iw62i3atLZosAYNZzT6Ca3BXfHLiKpBKr/1rz5dC2aFS7OgZ/c8Rsm44mgjEiQ2LPsHC3ZiKiEkzV04zpGoRDU5/B3MHGq/9WraL5ve/7kR1Q11tuclq0l4ebySnaJTXwqYqhTzWAu6t9Xxovtq+PtoE1dI8/+3drHP+oNzo2rGn+JBMWvtQaG8Y+bdc59HhxFXmKhRkWIiIrZDKZ0ayimQNbIE2Zgxb+3gCA9g1q4tiHppdssGXJ8+LtDMyb/0IrNPCpik93nseFNNM7YbvIZPD18rB7CbChTzWw8wx63Ig9YGGGhYjIgFfRTCTDzRpLGtutEWZa2aNJy1GZ9hpV3dG9WR2b9mWypGWAN+p6y1G7Ote7omJi3xWdGRYiIgMxH/dBQaEAD3dX641toA0MvDzcgaIaFkP2zDKytPGkLW2GPhWIkZ0bIvzn4/j7cq7ZdiQtr1mo0RIDBixERAbkbq6QO+DT8f/COyJNlYPmfprZTMtHtMfkX+LxTp/iWUuLXm6Da3ey8GQD6zUnHkUL6NWr4Wl2SMjW6Uoymczi7KeWAd7IzitEoVrQFQH3bF4HTXyr48e/rwPQ7C9Vv4YnzqWq8Pflu7a9MImW3F3cgy4MWIiIykmfJ+rqPW5W1wt/Te6md2xIx0D9k0wEEe/1bYZTKUr0DNHswfbpv1vj49/OGM00AkrskVTaThcZ1DYAb/VojLGrY3QBy8rRnQBAF7A0qVMd7/Rthrc3xpXx1UgMbKm1qkwMWIiIRGTWoCfw+soTGP9MY92xt3vrryNT19sDP4R3tHidVgEKxCVlmHzOlq8lm9qYaOTmIkMDn6q4djcLADCgtR+a1fXCuVsq7Dl32+R1+rfUrINz7pYKW+NSbHhlKg827HpRqRiwEBGJyDPNfXF2Tn/dFgSlNe1fIfD2dMPA1gHGTxZFGpZW8C1mX67mzJz+cHORoclHfwEAAmtWxZQ+zfDBrwm6NnMHt0SNqlUwqSgzU9fbA2O7NcLs7Wftei1yNHFnWEQeTxERSU9pgpWqVTT1LaFFmzVWl7thav8QPBHgbdS2cW3rGz/aQjuEULLA18PdFW4lf1U38R0YHhqE59sGGDWxpZi4PETP6IWoaT0r5bXFROSzmplhISJ6HJz4qA+Uj/IRUMPTbJtt47vg8u2H6NKkttXr2TNz2lKYYU9dRMnr/DCyA6pWccNrPx2zvSOl5K8wf8+kpKzT5csbAxYiosdANbmb1cxM+wY10b7EbCRLCY32NsxaKk/9WvrpPfbz9kDVKq7wqVYFMYkPAACjuwbBw90V3x28avY6R6b3AgB0/Wx/+XX2MSH2DAuHhIiIJOrDAS0AABN6Fhf4/v1BT6x9o5NuM0hbRmle7lAfAHSr/ppS1tGe7s1qY//7z6BDUHEg9cmglnq7dT8VVBNv92qCEU8Xr9pbr4Yn6pnIOpk6JnXcS4iIiESpVT0FLi/4F6b2L/7SD/SpqrcZ5Lv9mgEA3ggLNjpf+/3Ws7kv9r7bHdvGdylVP7RDETWqVinV+Vr+Ck+81685fL3Mr+Dbp0VdnJnTHyNDxb1IWmWoX1PcQRyHhIiIJMzSLtMA0DJAgYvzn4XczXjV32Z1i7cuaOLrpfdct6a18ffluxjSUZN9sSXB8p/ujXA+VYXn2vibb2TDhSxlc2QyTUGyvRmf7RO7IrdAjVdWRNt3ohVBtapi6bD2mPX7GZy6qXTote3FGhYiInJqhsHKHxPDkHAzA/0N6kxKWj26E7LyCjTbEQCoVd169qS63A0/WllfxlFsm9JdrE39GuXSDxeZDO0Ca2BSr6YYuyamXF7DFiNFviw/wICFiIjs1Lq+Aq3rKyy2cXGR6YIVAJjQswmu38nC8+2M14WxpXbCnh2vy6prk1p4t28zxCVlYP6O8465qDk27NJdEdo3qFHJPbCONSxERFTuvD3c8UN4RzzXpjhgmdy7KerV8MR/S6zqW95siWlcXVzQoaEP3KxMm6ni5oKng310jze/FYqVrz9Vxh5WjkpaAscuDFiIiKhSvNO3GaKm9UQdC0Wyhhy1Nq8tX9CWmnQK9sH5uc/i30/W0x17KshHt9+TVu3qVdDPYE+pksRdNSIuDFiIiKjS2Froqd1J+M1ujVC7ehX8p3sj42vZ8bq9igILLw/jyghL16nipulH18a14WolA9MywBsnPuqD50qs6hs/qy+iZ/QyaltZq/zqXr9SX902rGEhIiLRmvXcE/hfTDImF20AWcdLjuMf9oGLiWDBluBH26SFvzcOvP+MXnZHJtNkXrTbG5iy/70eiLp8Fy8WZVasxRkymUwvGKlRtQpqWO1l+apZ1R0PsvMruRf2Y8BCRESiNSYsGGMM1oAxFawAQLO6mqnVNau6m3we0C/eDTbYU+nw1J6IvnrPYjBSv2ZVDOtUvDCdxW0JHDjeU8dLjm5Naut2s57UuynOp6oQaWYHbFOquLng9wma6dkvfHNE77nKzvDYggELERE5td8ndMWBi+kYExYEABjeqQFiEh+gZ3Nfo7baoSVTAn2qItCnqsP6ZdvMJu3O2cX+fDsM97PyEP7zcQCaVXmjpvXEkSv3dAHLu301C/oFTd9hR380maWzt4zXexF/uMKAhYiInFzbwBpoG1hD99jD3RXfjHhSr838F1phbXQipv8rBLbSZmws8almfX0Zmwp8S7RpVc94yrhMJrO4doy7qwwTezaFfw0PfPDrKZNtLGV8qlURfzgg/h4SERGV0WudG+I1OxdHC2taG1+80tZi4NK3RV2M7hqEthYWlrO2KaWtLAU+1eVumNynKWJu3Ncde6dPMyTczMD+C+lmz5vxrxCcSlGif0vzM5nEggELERGRGS8VbexojouLDJ8MammxTa8QXzzfNgBtSiy298mgJ7Bw1wV8/nIbAECgT9n28TE1tDS5j6ZQ2XDYqGTgMyYs2Or2DGLBgIWIiMiB2gXWQHxyBoY8FQgAcHWRYdnw9nptRncNRnhokG5qdMsABZYMaWtxF2mLBb6l7KszrQPDgIWIiMiBNrz5NM6nqtA+sKbFdobruPz7ScvZnLIyVQQs9g0PS3KOPBAREZGTqFrFDR0a+pidfm2rjg01Ac+wokxNvRoeZbqeqdjEecIVZliIiIhEafWYTohPztDtV9TE1wtfDWsHXy/zgYu9y6k4UYKFAQsREZEYVZO7oWuT2nrHBrerp/c4xM8LF9Iy8Vwb/1K9hjMNCTFgISIiclIb3uyMvy/fQf+WfgCAoFrmF75zntDENAYsRERETsqnWhW9rIuvtwf+mBimt6ljFVcX5BWqdQvSOcEq/CYxYCEiInqMtK6vv1LujklhWPdPIsb3bFJJPXIMBixERESPsaZ1vTBncCvd45I7VDsTBixEREQS4qfwwPcjO8Dbw/yu1mJk1zosBQUFmDlzJoKDg+Hp6YlGjRph7ty5UKvVFs87dOgQOnToAA8PDzRq1AgrVqwoU6eJiIio9Pq39ENo41qV3Q272JVhWbhwIVasWIHVq1ejZcuWiImJwejRo6FQKDB58mST51y/fh0DBgzAm2++iXXr1uHIkSMYP3486tSpg5deeskhb4KIiIgeb3YFLNHR0Rg8eDAGDhwIAAgKCsLGjRsRExNj9pwVK1agQYMGWLp0KQCgRYsWiImJweLFixmwEBERkU3sGhIKCwvDvn37cOnSJQBAQkICoqKiMGDAALPnREdHo1+/fnrH+vfvj5iYGOTn55s8Jzc3FyqVSu+HiIiIpMuuDMu0adOgVCoREhICV1dXFBYWYsGCBRg+fLjZc9LS0lC3bl29Y3Xr1kVBQQHu3r0Lf3/j1fkiIiIwZ84ce7pGREREjzG7MiybNm3CunXrsGHDBsTGxmL16tVYvHgxVq9ebfE8w6V/haJVa8wtCTxjxgwolUrdT3Jysj3dJCIioseMXRmWqVOnYvr06Rg2bBgAoHXr1khMTERERARGjRpl8hw/Pz+kpaXpHUtPT4ebmxtq1TJdoSyXyyGXO+c8cSIiInI8uzIs2dnZcHHRP8XV1dXitObQ0FBERkbqHduzZw86duwId3fnmgNORERElcOugGXQoEFYsGABduzYgRs3bmDbtm1YsmQJXnzxRV2bGTNmIDw8XPf4rbfeQmJiIt59912cP38eP//8M3766Se8//77jnsXRERE9Fiza0ho+fLl+PjjjzF+/Hikp6cjICAA48aNw6xZs3RtUlNTkZSUpHscHByMnTt34p133sE333yDgIAALFu2jFOaiYiIyGYyQRD/vo0qlQoKhQJKpRLe3t6V3R0iIiKygSO/v+0aEiIiIiKqDAxYiIiISPQYsBAREZHo2VV0W1m0ZTZcop+IiMh5aL+3HVEu6xQBS2ZmJgAgMDCwkntCRERE9srMzIRCoSjTNZxilpBarcatW7fg5eVldjn/0lCpVAgMDERycjJnH1UA3u+KxftdsXi/Kx7vecUqzf0WBAGZmZkICAgwWnjWXk6RYXFxcUH9+vXL7fre3t78x16BeL8rFu93xeL9rni85xXL3vtd1syKFotuiYiISPQYsBAREZHoSTpgkcvl+OSTT7gzdAXh/a5YvN8Vi/e74vGeV6zKvt9OUXRLRERE0ibpDAsRERE5BwYsREREJHoMWIiIiEj0GLAQERGR6Ek6YPn2228RHBwMDw8PdOjQAX///Xdld0n0IiIi8NRTT8HLywu+vr544YUXcPHiRb02giBg9uzZCAgIgKenJ5555hmcPXtWr01ubi7efvtt1K5dG9WqVcPzzz+Pmzdv6rV58OABRo4cCYVCAYVCgZEjRyIjI6O836JoRUREQCaTYcqUKbpjvNeOl5KSgtdeew21atVC1apV0a5dO5w8eVL3PO+54xQUFGDmzJkIDg6Gp6cnGjVqhLlz50KtVuva8H6X3uHDhzFo0CAEBARAJpPht99+03u+Iu9tUlISBg0ahGrVqqF27dqYNGkS8vLy7HtDgkT98ssvgru7u/Djjz8K586dEyZPnixUq1ZNSExMrOyuiVr//v2FlStXCmfOnBHi4+OFgQMHCg0aNBAePnyoa/PZZ58JXl5ewpYtW4TTp08LQ4cOFfz9/QWVSqVr89Zbbwn16tUTIiMjhdjYWKFnz55C27ZthYKCAl2bZ599VmjVqpVw9OhR4ejRo0KrVq2E5557rkLfr1gcP35cCAoKEtq0aSNMnjxZd5z32rHu378vNGzYUHj99deFY8eOCdevXxf27t0rXLlyRdeG99xx5s+fL9SqVUv4888/hevXrwubN28WqlevLixdulTXhve79Hbu3Cl89NFHwpYtWwQAwrZt2/Ser6h7W1BQILRq1Uro2bOnEBsbK0RGRgoBAQHCxIkT7Xo/kg1YOnXqJLz11lt6x0JCQoTp06dXUo+cU3p6ugBAOHTokCAIgqBWqwU/Pz/hs88+07XJyckRFAqFsGLFCkEQBCEjI0Nwd3cXfvnlF12blJQUwcXFRdi1a5cgCIJw7tw5AYDwzz//6NpER0cLAIQLFy5UxFsTjczMTKFp06ZCZGSk0KNHD13AwnvteNOmTRPCwsLMPs977lgDBw4UxowZo3fs3//+t/Daa68JgsD77UiGAUtF3tudO3cKLi4uQkpKiq7Nxo0bBblcLiiVSpvfgySHhPLy8nDy5En069dP73i/fv1w9OjRSuqVc1IqlQAAHx8fAMD169eRlpamd2/lcjl69Oihu7cnT55Efn6+XpuAgAC0atVK1yY6OhoKhQJPP/20rk3nzp2hUCgk93c0YcIEDBw4EH369NE7znvteNu3b0fHjh3xyiuvwNfXF+3bt8ePP/6oe5733LHCwsKwb98+XLp0CQCQkJCAqKgoDBgwAADvd3mqyHsbHR2NVq1aISAgQNemf//+yM3N1RtutcYpNj90tLt376KwsBB169bVO163bl2kpaVVUq+cjyAIePfddxEWFoZWrVoBgO7+mbq3iYmJujZVqlRBzZo1jdpoz09LS4Ovr6/Ra/r6+krq7+iXX35BbGwsTpw4YfQc77XjXbt2Dd999x3effddfPjhhzh+/DgmTZoEuVyO8PBw3nMHmzZtGpRKJUJCQuDq6orCwkIsWLAAw4cPB8B/4+WpIu9tWlqa0evUrFkTVapUsev+SzJg0ZLJZHqPBUEwOkbmTZw4EadOnUJUVJTRc6W5t4ZtTLWX0t9RcnIyJk+ejD179sDDw8NsO95rx1Gr1ejYsSM+/fRTAED79u1x9uxZfPfddwgPD9e14z13jE2bNmHdunXYsGEDWrZsifj4eEyZMgUBAQEYNWqUrh3vd/mpqHvriPsvySGh2rVrw9XV1SiyS09PN4oCybS3334b27dvx4EDB1C/fn3dcT8/PwCweG/9/PyQl5eHBw8eWGxz+/Zto9e9c+eOZP6OTp48ifT0dHTo0AFubm5wc3PDoUOHsGzZMri5uenuA++14/j7++OJJ57QO9aiRQskJSUB4L9vR5s6dSqmT5+OYcOGoXXr1hg5ciTeeecdREREAOD9Lk8VeW/9/PyMXufBgwfIz8+36/5LMmCpUqUKOnTogMjISL3jkZGR6NKlSyX1yjkIgoCJEydi69at2L9/P4KDg/WeDw4Ohp+fn969zcvLw6FDh3T3tkOHDnB3d9drk5qaijNnzujahIaGQqlU4vjx47o2x44dg1KplMzfUe/evXH69GnEx8frfjp27IhXX30V8fHxaNSoEe+1g3Xt2tVomv6lS5fQsGFDAPz37WjZ2dlwcdH/GnJ1ddVNa+b9Lj8VeW9DQ0Nx5swZpKam6trs2bMHcrkcHTp0sL3TNpfnPma005p/+ukn4dy5c8KUKVOEatWqCTdu3Kjsronaf//7X0GhUAgHDx4UUlNTdT/Z2dm6Np999pmgUCiErVu3CqdPnxaGDx9ucqpc/fr1hb179wqxsbFCr169TE6Va9OmjRAdHS1ER0cLrVu3fuynIVpTcpaQIPBeO9rx48cFNzc3YcGCBcLly5eF9evXC1WrVhXWrVuna8N77jijRo0S6tWrp5vWvHXrVqF27drCBx98oGvD+116mZmZQlxcnBAXFycAEJYsWSLExcXplu+oqHurndbcu3dvITY2Vti7d69Qv359Tmu2xzfffCM0bNhQqFKlivDkk0/qpuaSeQBM/qxcuVLXRq1WC5988ong5+cnyOVyoXv37sLp06f1rvPo0SNh4sSJgo+Pj+Dp6Sk899xzQlJSkl6be/fuCa+++qrg5eUleHl5Ca+++qrw4MGDCniX4mUYsPBeO94ff/whtGrVSpDL5UJISIjwww8/6D3Pe+44KpVKmDx5stCgQQPBw8NDaNSokfDRRx8Jubm5uja836V34MABk5/Xo0aNEgShYu9tYmKiMHDgQMHT01Pw8fERJk6cKOTk5Nj1fmSCIAi252OIiIiIKp4ka1iIiIjIuTBgISIiItFjwEJERESix4CFiIiIRI8BCxEREYkeAxYiIiISPQYsREREJHoMWIiIiEj0GLAQERGR6DFgISIiItFjwEJERESix4CFiIiIRO//AXeOLeQgLZvAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('loss')\n",
    "plt.plot(program.losses, label='loss')\n",
    "plt.legend\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
