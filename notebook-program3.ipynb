{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for comet\n",
    "#from comet_ml import Experiment\n",
    "\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from dataset import ptb\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use gpu.\n"
     ]
    }
   ],
   "source": [
    "#device = 'cpu'\n",
    "device = 'gpu'\n",
    "\n",
    "np = numpy\n",
    "if device == 'gpu':\n",
    "    import cupy\n",
    "    import cupyx\n",
    "    np = cupy\n",
    "print(f'Use {device}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x, ndim=-1):\n",
    "    x = x.astype('float64')\n",
    "    if x.ndim == -1:\n",
    "        ndim = len(x.shape) - 1\n",
    "    c = x.max()\n",
    "    exp_x = np.exp(x - c)\n",
    "    sum_exp_x = np.sum(exp_x, axis=ndim)\n",
    "    out = (exp_x.T / sum_exp_x).T\n",
    "    return out.astype('f')\n",
    "\n",
    "def cross_entropy_error(y, t, onehot=False):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "    batch_size = y.shape[0]\n",
    "    if not onehot:\n",
    "        out = -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "    else:\n",
    "        out = -np.sum(np.dot(t, np.log(y + 1e-7))) / batch_size\n",
    "    return out\n",
    "\n",
    "def numerical_diff(f, x, i):\n",
    "    h = 1e-4\n",
    "    h_vec = np.zeros_like(x)\n",
    "    h_vec[i] = h\n",
    "    return (f(x + h_vec) - f(x - h_vec)) / (2*h)\n",
    "\n",
    "def numerical_diff2(f, x, i, j):\n",
    "    h = 1e-4\n",
    "    h_vec = np.zeros_like(x)\n",
    "    h_vec[i, j] = h\n",
    "    return (f(x + h_vec) - f(x - h_vec)) / (2*h)\n",
    "\n",
    "def numerical_gradient(f, x):\n",
    "    grad = np.zeros_like(x).astype(np.float128)\n",
    "    n, m = x.shape\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            grad[i, j] = numerical_diff2(f, x, i, j)\n",
    "    return grad\n",
    "\n",
    "def clip_grads(grads, max_norm):\n",
    "    total_norm = 0\n",
    "    for grad in grads:\n",
    "        total_norm += np.sum(grad ** 2)\n",
    "    total_norm = np.sqrt(total_norm)\n",
    "    rate = max_norm / (total_norm + 1e-6)\n",
    "    if rate < 1:\n",
    "        for grad in grads:\n",
    "            grad *= rate\n",
    "\n",
    "def to_cpu(x):\n",
    "    if type(x) == numpy.ndarray:\n",
    "        return x\n",
    "    return cupy.asnumpy(x)\n",
    "\n",
    "def to_gpu(x):\n",
    "    if type(x) == cupy.ndarray:\n",
    "        return x\n",
    "    return cupy.array(x)\n",
    "\n",
    "def to_device(x, device=device):\n",
    "    if device == 'gpu':\n",
    "        return to_gpu(x)\n",
    "    else:\n",
    "        return to_cpu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, shape, alpha=0.001, beta1=0.9, beta2=0.999, epsilon=10**(-8)):\n",
    "        self.alpha = alpha\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.m = np.zeros(shape)\n",
    "        self.v = np.zeros(shape)\n",
    "        self.t = 0\n",
    "\n",
    "    def update(self, w, dw):\n",
    "        self.t += 1\n",
    "        self.m = (self.beta1 * self.m) + (1 - self.beta1) * dw\n",
    "        self.v = (self.beta2 * self.v) + (1 - self.beta2) * dw**2\n",
    "        mh = self.m / (1 - self.beta1 ** self.t)\n",
    "        vh = self.v / (1 - self.beta2 ** self.t)\n",
    "        w -= self.alpha * (mh / (np.sqrt(vh) + self.epsilon))\n",
    "\n",
    "class AdamContainer:\n",
    "    def __init__(self, layers, alpha=0.001, beta1=0.9, beta2=0.999, epsilon=10**(-8)):\n",
    "        self.params = []\n",
    "        for params in [layer.params for layer in layers]:\n",
    "            for param in params:\n",
    "                self.params.append(param)\n",
    "        self.grads = []\n",
    "        for grads in [layer.grads for layer in layers]:\n",
    "            for grad in grads:\n",
    "                self.grads.append(grad)\n",
    "        self.adams = [Adam(param.shape, alpha, beta1, beta2, epsilon) for param in self.params]\n",
    "    \n",
    "    def update(self):\n",
    "        for adam, param, grad in zip(self.adams, self.params, self.grads):\n",
    "            adam.update(param, grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class BaseLayer:\n",
    "    def __init__(self):\n",
    "        self.params = None\n",
    "        self.grads = None\n",
    "        \n",
    "    def to_cpu(self):\n",
    "        for param in self.params:\n",
    "            param = to_cpu(param)\n",
    "        for grad in self.grads:\n",
    "            grad = to_cpu(grad)\n",
    "            \n",
    "    def to_gpu(self):\n",
    "        for param in self.params:\n",
    "            param = to_gpu(param)\n",
    "        for grad in self.grads:\n",
    "            grad = to_gpu(grad)\n",
    "\n",
    "class Affine(BaseLayer):\n",
    "    def __init__(self, w, b):\n",
    "        self.params = [w, b]\n",
    "        self.grads = [np.zeros_like(w), np.zeros_like(b)]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        w, b = self.params\n",
    "        self.x = x\n",
    "        return np.dot(x, w) + b\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        w = self.params[0]\n",
    "        dx = np.dot(dout, w.T)\n",
    "        self.grads[0] = self.dw = np.dot(self.x.T, dout)\n",
    "        self.grads[1] = self.db = np.sum(dout, axis=0)\n",
    "        return dx\n",
    "\n",
    "class TimeAffine(BaseLayer):\n",
    "    def __init__(self, w, b):\n",
    "        self.params = [w, b]\n",
    "        self.grads = [np.zeros_like(w), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        w, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, V = w.shape\n",
    "        \n",
    "        out = np.empty((N, T, V), dtype='f')\n",
    "        self.layers = []\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = Affine(w, b)\n",
    "            out[:,t,:] = layer.forward(xs[:,t,:])\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        self.cache = (N, T, D, V)\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        N, T, D, V = self.cache\n",
    "        \n",
    "        out = np.empty((N, T, D), dtype='f')\n",
    "        dw = np.empty((D, T, V), dtype='f')\n",
    "        db = np.empty((T, V), dtype='f')\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            out[:,t,:] = layer.backward(dout[:,t,:])\n",
    "            dw[:,t,:] = layer.dw\n",
    "            db[t,:] = layer.db\n",
    "        self.grads[0] = self.dw = dw.sum(axis=1)\n",
    "        self.grads[1] = self.db = db.sum(axis=0)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ReLU(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout[self.mask] = 0\n",
    "        return dout\n",
    "\n",
    "class Sigmoid(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.out = sigmoid(x)\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = dout * self.out * (1 - self.out)\n",
    "        return dx\n",
    "    \n",
    "class Softmax(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.y = softmax(x)\n",
    "        return self.y\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dx = self.y * dout\n",
    "        sumdx = np.sum(dx, axis=1, keepdims=True)\n",
    "        dx -= self.y * sumdx\n",
    "        return dx\n",
    "\n",
    "class SoftmaxWithLoss(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self, dout=1, onehot=False):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if not onehot:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx *= dout\n",
    "            dx = dx / batch_size\n",
    "        else:\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        return dx\n",
    "\n",
    "class TimeSoftmaxWithLoss(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.layers = None\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, xs, ts):\n",
    "        N, T, V = xs.shape\n",
    "        \n",
    "        # if ts is one-hot vector\n",
    "        if ts.ndim == 3:\n",
    "            ts = ts.argmax(axis=2).reshape(N, T)\n",
    "        \n",
    "        ys = np.empty(T, dtype='f')\n",
    "        self.layers = []\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = SoftmaxWithLoss()\n",
    "            ys[t] = layer.forward(xs[:,t,:], ts[:,t])\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        loss = ys.sum() / T\n",
    "        \n",
    "        self.cache = (N, T, V)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self):\n",
    "        N, T, V = self.cache\n",
    "        dx = np.empty((N, T, V), dtype='f')\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            dx[:,t,:] = layer.backward()\n",
    "        self.dx = dx / T\n",
    "        \n",
    "        return self.dx\n",
    "\n",
    "class Dropout(BaseLayer):\n",
    "    def __init__(self, ratio=0.5):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.ratio = ratio\n",
    "        self.mask = None\n",
    "        self.train = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.train:\n",
    "            self.mask = np.random.rand(*x.shape) > self.ratio\n",
    "            self.mask = self.mask.astype('f') / (1.0 - self.ratio)\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask\n",
    "\n",
    "class Embedding(BaseLayer):\n",
    "    def __init__(self, w):\n",
    "        self.params = [w]\n",
    "        self.grads = [np.zeros_like(w)]\n",
    "        self.idx = None\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        w = self.params[0]\n",
    "        self.idx = idx\n",
    "        return w[idx]\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        if device == 'gpu':\n",
    "            add_at = cupyx.scatter_add\n",
    "        else:\n",
    "            add_at = np.add.at\n",
    "            \n",
    "        dw = self.grads[0]\n",
    "        dw[...] = 0\n",
    "        add_at(dw, self.idx, dout)\n",
    "        self.grads[0] = self.dw = dw\n",
    "        return None\n",
    "\n",
    "class TimeEmbedding(BaseLayer):\n",
    "    def __init__(self, w):\n",
    "        self.params = [w]\n",
    "        self.grads = [np.zeros_like(w)]\n",
    "        self.layers = None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        w = self.params[0]\n",
    "        N, T = xs.shape\n",
    "        V, D = w.shape\n",
    "        \n",
    "        out = np.empty((N, T, D), dtype='f')\n",
    "        self.layers = []\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = Embedding(w)\n",
    "            out[:,t,:] = layer.forward(xs[:,t])\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        N, T, D = dout.shape\n",
    "        \n",
    "        dw = 0\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            layer.backward(dout[:,t,:])\n",
    "            dw += layer.dw\n",
    "        self.grads[0] = self.dw = dw\n",
    "        \n",
    "        return None\n",
    "\n",
    "class RNN(BaseLayer):\n",
    "    def __init__(self, wx, wh, b):\n",
    "        self.params = [wx, wh, b]\n",
    "        self.grads = [np.zeros_like(wx), np.zeros_like(wh), np.zeros_like(b)]\n",
    "    \n",
    "    def forward(self, x, h_prev):\n",
    "        wx, wh, b = self.params\n",
    "        t = np.dot(h_prev, wh) + np.dot(x, wx) + b\n",
    "        h_next = np.tanh(t)\n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "    \n",
    "    def backward(self, dh_next):\n",
    "        wx, wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "        \n",
    "        dt = dh_next * (1 - dh_next ** 2)\n",
    "        db = np.sum(dt, axis=0)\n",
    "        dwh = np.dot(h_prev.T, dt)\n",
    "        dh_prev = np.dot(dt, wh.T)\n",
    "        dwx = np.dot(x.T, dt)\n",
    "        dx = np.dot(dt, wx.T)\n",
    "        self.grads[0][...] = self.dwx = dwx\n",
    "        self.grads[1][...] = self.dwh = dwh\n",
    "        self.grads[2][...] = self.db = db\n",
    "        \n",
    "        return dx, dh_prev\n",
    "\n",
    "class TimeRNN(BaseLayer):\n",
    "    def __init__(self, wx, wh, b, stateful=False):\n",
    "        self.params = [wx, wh, b]\n",
    "        self.grads = [np.zeros_like(wx), np.zeros_like(wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        self.h, self.dh = None, None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h = None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        wx, wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = wx.shape\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:,t,:], self.h)\n",
    "            hs[:,t,:] = self.h\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        return hs\n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        wx, wh, b  = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = wx.shape\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:,t,:] + dh)\n",
    "            dxs[:,t,:] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "        \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dwx = self.grads[0]\n",
    "        self.dwh = self.grads[1]\n",
    "        self.db = self.grads[2]\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs\n",
    "\n",
    "class LSTM(BaseLayer):\n",
    "    def __init__(self, wx, wh, b):\n",
    "        self.params = [wx, wh, b]\n",
    "        self.grads = [np.zeros_like(wx), np.zeros_like(wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, x, h_prev, c_prev):\n",
    "        wx, wh, b = self.params\n",
    "        N, H = h_prev.shape\n",
    "        \n",
    "        A = np.dot(h_prev, wh) + np.dot(x, wx) + b\n",
    "        \n",
    "        f = A[:, :H]\n",
    "        g = A[:, H:2*H]\n",
    "        i = A[:, 2*H:3*H]\n",
    "        o = A[:, 3*H:]\n",
    "        \n",
    "        f = sigmoid(f)\n",
    "        g = np.tanh(g)\n",
    "        i = sigmoid(i)\n",
    "        o = sigmoid(o)\n",
    "        \n",
    "        c_next = f * c_prev + g * i\n",
    "        h_next = o * np.tanh(c_next)\n",
    "        \n",
    "        self.cache = (x, h_prev, c_prev,i, f, g, o, c_next)\n",
    "        return h_next, c_next\n",
    "    \n",
    "    def backward(self, dh_next, dc_next):\n",
    "        wx, wh, b = self.params\n",
    "        x, h_prev, c_prev, i, f, g, o, c_next = self.cache\n",
    "        \n",
    "        tanh_c_next = np.tanh(c_next)\n",
    "        ds = dc_next + (dh_next * o) * (1 - tanh_c_next ** 2)\n",
    "        \n",
    "        dc_prev = ds * f\n",
    "        di = ds * g\n",
    "        df = ds * c_prev\n",
    "        do = dh_next * tanh_c_next\n",
    "        dg = ds * i\n",
    "        \n",
    "        di *= i * (1 - i)\n",
    "        df *= f * (1 - f)\n",
    "        do *= o * (1 - o)\n",
    "        dg *= 1 - g ** 2\n",
    "        \n",
    "        dA = np.hstack((df, dg, di, do))\n",
    "        \n",
    "        dwh = np.dot(h_prev.T, dA)\n",
    "        dh_prev = np.dot(dA, wh.T)\n",
    "        dwx = np.dot(x.T, dA)\n",
    "        dx = np.dot(dA, wx.T)\n",
    "        db = dA.sum(axis=0)\n",
    "        \n",
    "        self.grads[0][...] = self.dwx = dwx\n",
    "        self.grads[1][...] = self.dwh = dwh\n",
    "        self.grads[2][...] = self.db = db\n",
    "        \n",
    "        return dx, dh_prev, dc_prev\n",
    "\n",
    "class TimeLSTM(BaseLayer):\n",
    "    def __init__(self, wx, wh, b, stateful=False):\n",
    "        self.params = [wx, wh, b]\n",
    "        self.grads = [np.zeros_like(wx), np.zeros_like(wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        self.h, self.dh, self.c = None, None, None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "    def set_state(self, h, c=None):\n",
    "        self.h, self.c = h, c\n",
    "        \n",
    "    def reset_state(self):\n",
    "        self.h, self.c = None, None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        wx, wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        H = wh.shape[0]\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "        if not self.stateful or self.c is None:\n",
    "            self.c = np.zeros((N, H), dtype='f')\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = LSTM(*self.params)\n",
    "            self.h, self.c = layer.forward(xs[:,t,:], self.h, self.c)\n",
    "            hs[:,t,:] = self.h\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        return hs\n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        wx, wh, b  = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D = wx.shape[0]\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh, dc = 0, 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh, dc = layer.backward(dhs[:,t,:] + dh, dc)\n",
    "            dxs[:,t,:] = dx\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "        \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dwx = self.grads[0]\n",
    "        self.dwh = self.grads[1]\n",
    "        self.db = self.grads[2]\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs\n",
    "\n",
    "class BaseNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = None\n",
    "        self.lastLayer = None\n",
    "        self.adam = None\n",
    "        \n",
    "    def train(self, x, t):\n",
    "        # forward\n",
    "        loss = self.loss(x, t)\n",
    "        \n",
    "        # backward\n",
    "        dout = self.lastLayer.backward()\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "        \n",
    "        self.update()\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def update(self):\n",
    "        for grads in [layer.grads for layer in self.layers.values()]:\n",
    "            clip_grads(grads, self.max_grad)\n",
    "        self.adam.update()\n",
    "    \n",
    "    def save(self, state_file_name = 'network.state.pkl'):\n",
    "        params = self.adam.params.copy()\n",
    "        for i, param in enumerate(params):\n",
    "            params[i] = to_cpu(params[i])\n",
    "            \n",
    "        with open(state_file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "            print(f'Saved: {state_file_name}')\n",
    "            \n",
    "    def load(self, state_file_name = 'network.state.pkl'):\n",
    "        if os.path.exists(state_file_name):\n",
    "            with open(state_file_name, 'rb') as f:\n",
    "                params = pickle.load(f)\n",
    "                for i, param in enumerate(params):\n",
    "                    self.adam.params[i][:] = to_device(param, device)\n",
    "                print(f'Loaded: {state_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(BaseLayer):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed_w = (rn(V, D) / 100).astype('f')\n",
    "        lstm_wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Embedding'] = TimeEmbedding(embed_w)\n",
    "        self.layers['LSTM'] = TimeLSTM(lstm_wx, lstm_wh, lstm_b, stateful=False)\n",
    "        \n",
    "        self.params = []\n",
    "        for params in [layer.params for layer in self.layers.values()]:\n",
    "            for param in params:\n",
    "                self.params.append(param)\n",
    "        self.grads = []\n",
    "        for grads in [layer.grads for layer in self.layers.values()]:\n",
    "            for grad in grads:\n",
    "                self.grads.append(grad)\n",
    "        self.hs = None\n",
    "        \n",
    "    def forward(self, xs):\n",
    "        for layer in self.layers.values():\n",
    "            xs = layer.forward(xs)\n",
    "        self.hs = xs\n",
    "        return xs[:,-1,:]\n",
    "    \n",
    "    def backward(self, dh):\n",
    "        dhs = np.zeros_like(self.hs)\n",
    "        dhs[:,-1,:] = dh\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dhs = layer.backward(dhs)\n",
    "        return dhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightSum(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, hs, a):\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        ar = a.reshape(N, T, 1) #.repeat(H, axis=2)\n",
    "        t = hs * ar\n",
    "        c = np.sum(t, axis=1)\n",
    "        \n",
    "        self.cache = (hs, ar)\n",
    "        return c\n",
    "    \n",
    "    def backward(self, dc):\n",
    "        hs, ar = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        dt = dc.reshape(N, 1, H).repeat(T, axis=1)\n",
    "        dar = dt * hs\n",
    "        dhs = dt * ar\n",
    "        da = np.sum(dar, axis=2)\n",
    "        \n",
    "        return dhs, da\n",
    "\n",
    "class AttentionWeight(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.softmax = Softmax()\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, hs, h):\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        hr = h.reshape(N, 1, H) #.repeat(T, axis=1)\n",
    "        t = hs * hr\n",
    "        s = np.sum(t, axis=2)\n",
    "        a = self.softmax.forward(s)\n",
    "        \n",
    "        self.cache = (hs, hr)\n",
    "        return a\n",
    "        \n",
    "    def backward(self, da):\n",
    "        hs, hr = self.cache\n",
    "        N, T, H = hs.shape\n",
    "        \n",
    "        ds = self.softmax.backward(da)\n",
    "        dt = ds.reshape(N, T, 1).repeat(H, axis=2)\n",
    "        dhs = dt * hr\n",
    "        dhr = dt * hs\n",
    "        dh = np.sum(dhr, axis=1)\n",
    "        \n",
    "        return dhs, dh\n",
    "\n",
    "class Attention(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.attention_weight_layer = AttentionWeight()\n",
    "        self.weight_sum_layer = WeightSum()\n",
    "        self.attention_weight = None\n",
    "    \n",
    "    def forward(self, hs, h):\n",
    "        a = self.attention_weight_layer.forward(hs, h)\n",
    "        out = self.weight_sum_layer.forward(hs, a)\n",
    "        self.attention_weight = a\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dhs0, da = self.weight_sum_layer.backward(dout)\n",
    "        dhs1, dh = self.attention_weight_layer.backward(da)\n",
    "        dhs = dhs0 + dhs1\n",
    "        return dhs, dh\n",
    "\n",
    "class TimeAttention(BaseLayer):\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.grads = []\n",
    "        self.layers = None\n",
    "        self.attention_weights = None\n",
    "        \n",
    "    def forward(self, hs_enc, hs_dec):\n",
    "        N, T, H = hs_dec.shape\n",
    "        out = np.empty_like(hs_dec)\n",
    "        self.layers = []\n",
    "        self.attention_weights = []\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = Attention()\n",
    "            out[:, t, :] = layer.forward(hs_enc, hs_dec[:, t, :])\n",
    "            self.layers.append(layer)\n",
    "            self.attention_weights.append(layer.attention_weight)\n",
    "            \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        N, T, H = dout.shape\n",
    "        dhs_enc = 0\n",
    "        dhs_dec = np.empty_like(dout)\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            dhs, dh = layer.backward(dout[:, t, :])\n",
    "            dhs_enc += dhs\n",
    "            dhs_dec[:, t, :] = dh\n",
    "        \n",
    "        return dhs_enc, dhs_dec\n",
    "\n",
    "class AttentionEncoder(Encoder):\n",
    "    def forward(self, xs):\n",
    "        for layer in self.layers.values():\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dhs = layer.backward(dhs)\n",
    "        return dhs\n",
    "\n",
    "class AttentionDecoder(BaseLayer):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed_w = (rn(V, D) / 100).astype('f')\n",
    "        lstm_wx = (rn(D, 4 * H) / np.sqrt(D)).astype('f')\n",
    "        lstm_wh = (rn(H, 4 * H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b = np.zeros(4 * H).astype('f')\n",
    "        \n",
    "        affine_w = (rn(2 * H, V) / np.sqrt(2 * H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Embedding'] = TimeEmbedding(embed_w)\n",
    "        self.layers['LSTM'] = TimeLSTM(lstm_wx, lstm_wh, lstm_b, stateful=True)\n",
    "        self.layers['Attention'] = TimeAttention()\n",
    "        self.layers['Affine'] = TimeAffine(affine_w, affine_b)\n",
    "        \n",
    "        self.params = []\n",
    "        for params in [layer.params for layer in self.layers.values()]:\n",
    "            for param in params:\n",
    "                self.params.append(param)\n",
    "        self.grads = []\n",
    "        for grads in [layer.grads for layer in self.layers.values()]:\n",
    "            for grad in grads:\n",
    "                self.grads.append(grad)\n",
    "        \n",
    "    def forward(self, xs, enc_hs):\n",
    "        h = enc_hs[:, -1]\n",
    "        self.layers['LSTM'].set_state(h)\n",
    "        \n",
    "        out = self.layers['Embedding'].forward(xs)\n",
    "        dec_hs = self.layers['LSTM'].forward(out)\n",
    "        c = self.layers['Attention'].forward(enc_hs, dec_hs)\n",
    "        out = np.concatenate((c, dec_hs), axis=2)\n",
    "        score = self.layers['Affine'].forward(out)\n",
    "        return score\n",
    "    \n",
    "    def backward(self, dscore):\n",
    "        dout = self.layers['Affine'].backward(dscore)\n",
    "        N, T, H2 = dout.shape\n",
    "        H = H2 // 2\n",
    "        dc, ddec_hs0 = dout[:, :, :H], dout[: ,: ,H:]\n",
    "        denc_hs, ddec_hs1 = self.layers['Attention'].backward(dc)\n",
    "        ddec_hs = ddec_hs0 + ddec_hs1\n",
    "        dout = self.layers['LSTM'].backward(ddec_hs)\n",
    "        denc_hs[:, -1] += self.layers['LSTM'].dh\n",
    "        self.layers['Embedding'].backward(dout)\n",
    "\n",
    "        return denc_hs\n",
    "\n",
    "    def generate(self, enc_hs, start_id, sample_size):\n",
    "        sampled = []\n",
    "        sample_id = start_id\n",
    "        h = enc_hs[:,  -1]\n",
    "        self.layers['LSTM'].set_state(h)\n",
    "\n",
    "        for _ in range(sample_size):\n",
    "            x = np.array(sample_id).reshape(1, 1)\n",
    "            out = self.layers['Embedding'].forward(x)\n",
    "            dec_hs = self.layers['LSTM'].forward(out)\n",
    "            c = self.layers['Attention'].forward(enc_hs, dec_hs)\n",
    "            out = np.concatenate((c, dec_hs), axis=2)\n",
    "            score = self.layers['Affine'].forward(out)\n",
    "\n",
    "            sample_id = np.argmax(score.flatten())\n",
    "            sampled.append(sample_id)\n",
    "\n",
    "        return np.array(sampled)\n",
    "\n",
    "class AttentionSeq2SeqNetwork(BaseNetwork):\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size, max_grad=5.0):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        self.max_grad = max_grad\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Encoder'] = AttentionEncoder(V, D, H)\n",
    "        self.layers['Decoder'] = AttentionDecoder(V, D, H)\n",
    "        self.lastLayer = TimeSoftmaxWithLoss()\n",
    "        self.adam = AdamContainer(list(self.layers.values()))\n",
    "        \n",
    "    def generate(self, xs, start_id, sample_size):\n",
    "        h = self.layers['Encoder'].forward(xs)\n",
    "        sampled = self.layers['Decoder'].generate(h, start_id, sample_size)\n",
    "        return sampled\n",
    "        \n",
    "    def loss(self, xs, ts):\n",
    "        decoder_xs, decoder_ts = ts[:, :-1], ts[:, 1:]\n",
    "        h = self.layers['Encoder'].forward(xs)\n",
    "        score = self.layers['Decoder'].forward(decoder_xs, h)\n",
    "        loss = self.lastLayer.forward(score, decoder_ts)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_date_question(max_daydelta=10000):\n",
    "    today = datetime.date.today()\n",
    "    date = today + datetime.timedelta(days=random.randint(-max_daydelta, max_daydelta))\n",
    "    question = date.strftime('%Y %B %d %A')\n",
    "    correct = '=' + date.strftime('%Y-%m-%d')\n",
    "    question = question.ljust(29)\n",
    "    correct = correct.ljust(1+10+1)\n",
    "    return question, correct\n",
    "\n",
    "def make_date_questions(question_num):\n",
    "    questions =  []\n",
    "    corrects = []\n",
    "    char_to_id = {}\n",
    "    \n",
    "    index = 0\n",
    "    for number in range(10):\n",
    "        char_to_id[f'{number}'] = index\n",
    "        index += 1\n",
    "    for alphabet in range(26):\n",
    "        char_to_id[f'{chr(ord(\"a\") + alphabet)}'] = index\n",
    "        char_to_id[f'{chr(ord(\"A\") + alphabet)}'] = index + 1\n",
    "        index += 2\n",
    "    char_to_id['='] = index\n",
    "    char_to_id['-'] = index + 1\n",
    "    char_to_id[' '] = index + 2\n",
    "    \n",
    "    for _ in range(question_num):\n",
    "        q, c = generate_date_question()\n",
    "        q = [char_to_id[s] for s in q]\n",
    "        c = [char_to_id[s] for s in c]\n",
    "        questions.append(q)\n",
    "        corrects.append(c)\n",
    "    questions = np.array(questions)\n",
    "    corrects = np.array(corrects)\n",
    "    \n",
    "    id_to_char = dict(zip(char_to_id.values(), char_to_id.keys()))\n",
    "    \n",
    "    return questions[:, ::-1], corrects, char_to_id, id_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Program3:\n",
    "    def __init__(self):\n",
    "        sample_size = 50000\n",
    "        self.questions, self.corrects, self.char_to_id, self.id_to_char = make_date_questions(sample_size)\n",
    "        self.params = OrderedDict({'vocab_size': len(self.char_to_id), 'wordvec_size': 16, 'hidden_size': 256,\n",
    "                                   'max_grad': 5.0, 'max_epoch': 80, 'sample_size': sample_size, 'batch_size': 128})\n",
    "        self.net = AttentionSeq2SeqNetwork(self.params['vocab_size'], self.params['wordvec_size'], self.params['hidden_size'], self.params['max_grad'])\n",
    "        self.losses = []\n",
    "        \n",
    "    def fit(self, x, t, batch_size):\n",
    "        data_size = len(x)\n",
    "        max_iters = data_size // batch_size\n",
    "        \n",
    "        for iters in tqdm(range(max_iters)):\n",
    "            batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
    "            batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
    "\n",
    "            loss = self.net.train(batch_x, batch_t)\n",
    "            self.losses.append(loss.tolist())\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def visualize(self, attention_map, row_labels, column_labels):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.pcolor(attention_map, cmap=plt.cm.Greys_r, vmin=0.0, vmax=1.0)\n",
    "\n",
    "        ax.patch.set_facecolor('black')\n",
    "        ax.set_yticks(np.arange(attention_map.shape[0])+0.5, minor=False)\n",
    "        ax.set_xticks(np.arange(attention_map.shape[1])+0.5, minor=False)\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_xticklabels(row_labels, minor=False)\n",
    "        ax.set_yticklabels(column_labels, minor=False)\n",
    "\n",
    "        plt.savefig('figure.png')\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "        print('Saved: figure.png')\n",
    "    \n",
    "    def save_figure(self):\n",
    "        global np, device\n",
    "        device_changed = False\n",
    "        \n",
    "        temp_file_name = 'temp.state.pkl'\n",
    "        self.net.save(temp_file_name)\n",
    "        \n",
    "        if device == 'gpu':\n",
    "            print('Change to cpu.')\n",
    "            device = 'cpu'\n",
    "            np = numpy\n",
    "            device_changed = True\n",
    "        \n",
    "        _program = Program3()\n",
    "        _program.net.load(temp_file_name)\n",
    "        \n",
    "        for i in tqdm(range(len(_program.questions))):\n",
    "            question = to_cpu(_program.questions[[i]])\n",
    "            correct = to_cpu(_program.corrects[[i]])\n",
    "            answer = _program.net.generate(question, start_id=self.char_to_id['='], sample_size=10)\n",
    "            _program.net.loss(question, correct)\n",
    "            question = [_program.id_to_char[x] for x in question[0, ::-1]]\n",
    "            correct = [_program.id_to_char[x] for x in correct[0, 1:-1]]\n",
    "            answer = [_program.id_to_char[x] for x in answer]\n",
    "            if answer != correct:\n",
    "                  continue\n",
    "            \n",
    "            attention_map = np.array(_program.net.layers['Decoder'].layers['Attention'].attention_weights)\n",
    "            attention_map = attention_map[:, 0, :].reshape(attention_map.shape[0], attention_map.shape[2])\n",
    "            attention_map = attention_map[:-1, ::-1]\n",
    "            _program.visualize(attention_map, question, correct)\n",
    "            break\n",
    "                  \n",
    "        if device_changed:\n",
    "            print('Change to gpu.')\n",
    "            device = 'gpu'\n",
    "            np = cupy\n",
    "        \n",
    "        os.remove(temp_file_name)\n",
    "        \n",
    "    def __call__(self):\n",
    "        ## for comet\n",
    "        #experiment = Experiment()\n",
    "        #experiment.log_parameters(self.params)\n",
    "        \n",
    "        for key in self.params.keys() :\n",
    "            print(f'{key}: {self.params[key]}')\n",
    "        vocab_size, wordvec_size, hidden_size, max_grad, max_epoch, sample_size, batch_size = self.params.values()\n",
    "\n",
    "        self.net.load()\n",
    "        \n",
    "        for epoch in range(max_epoch):\n",
    "            loss = self.fit(self.questions, self.corrects, batch_size)\n",
    "            \n",
    "            correct_num = 0\n",
    "            test_num = 3\n",
    "            for _ in range(test_num):\n",
    "                questions, corrects, _, _ = make_date_questions(1)\n",
    "                answer = self.net.generate(questions, start_id=self.char_to_id['='], sample_size=10)\n",
    "                question = ''.join([self.id_to_char[x] for x in to_cpu(questions[0, ::-1])])\n",
    "                correct = ''.join([self.id_to_char[x] for x in to_cpu(corrects[0, 1:-1])])\n",
    "                answer = ''.join([self.id_to_char[x] for x in to_cpu(answer)])\n",
    "                is_correct = True if answer == correct else False\n",
    "                correct_num += 1 if is_correct else 0\n",
    "                print(f'{\"○\" if is_correct else \"×\"} {question} = {answer} [{correct}]')\n",
    "            print(f'[{epoch}] Corrects {correct_num} / {test_num}\\tloss: {loss}')\n",
    "            \n",
    "            ## for comet\n",
    "            #experiment.log_metric('loss', loss, step=epoch)\n",
    "        \n",
    "        self.net.save()\n",
    "        self.exam()\n",
    "        self.save_figure()\n",
    "\n",
    "        ## for comet\n",
    "        #experiment.end()\n",
    "    \n",
    "    def exam(self, question_num=100):\n",
    "        correct_num = 0\n",
    "        for _ in range(question_num):\n",
    "            questions, corrects, _, _ = make_date_questions(1)\n",
    "            answer = self.net.generate(questions, start_id=self.char_to_id['='], sample_size=10)\n",
    "            question = ''.join([self.id_to_char[x] for x in to_cpu(questions[0, ::-1])])\n",
    "            correct = ''.join([self.id_to_char[x] for x in to_cpu(corrects[0, 1:-1])])\n",
    "            answer = ''.join([self.id_to_char[x] for x in to_cpu(answer)])\n",
    "            is_correct = True if answer == correct else False\n",
    "            correct_num += 1 if is_correct else 0\n",
    "            print(f'{\"○\" if is_correct else \"×\"} {question} = {answer} [{correct}]')\n",
    "        print(f'Score: {correct_num} / {question_num}\\tAccuracy: {(correct_num / question_num)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 65\n",
      "wordvec_size: 16\n",
      "hidden_size: 256\n",
      "max_grad: 5.0\n",
      "max_epoch: 80\n",
      "sample_size: 50000\n",
      "batch_size: 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:23<00:00, 16.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2008 March 13 Thursday        = 2019-01-11 [2008-03-13]\n",
      "× 2044 June 05 Sunday           = 2019-01-11 [2044-06-05]\n",
      "× 2044 January 13 Wednesday     = 2019-01-11 [2044-01-13]\n",
      "[0] Corrects 0 / 3\tloss: 1.0557314157485962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:23<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2012 July 18 Wednesday        = 2010-01-11 [2012-07-18]\n",
      "× 2038 March 24 Wednesday       = 2010-01-11 [2038-03-24]\n",
      "× 2016 February 10 Wednesday    = 2010-01-11 [2016-02-10]\n",
      "[1] Corrects 0 / 3\tloss: 1.0305585861206055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:24<00:00, 15.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2015 April 29 Wednesday       = 2010-01-11 [2015-04-29]\n",
      "× 2005 September 29 Thursday    = 2010-01-11 [2005-09-29]\n",
      "× 2027 June 21 Monday           = 2010-01-11 [2027-06-21]\n",
      "[2] Corrects 0 / 3\tloss: 1.0139365196228027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:24<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2002 November 16 Saturday     = 2019-01-11 [2002-11-16]\n",
      "× 1997 March 13 Thursday        = 2019-01-11 [1997-03-13]\n",
      "× 2022 August 07 Sunday         = 2019-01-11 [2022-08-07]\n",
      "[3] Corrects 0 / 3\tloss: 1.0188044309616089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:25<00:00, 15.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2020 November 20 Friday       = 2000-01-11 [2020-11-20]\n",
      "× 2002 March 30 Saturday        = 2000-01-11 [2002-03-30]\n",
      "× 2006 March 10 Friday          = 2000-01-11 [2006-03-10]\n",
      "[4] Corrects 0 / 3\tloss: 1.0016144514083862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:25<00:00, 15.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2008 November 06 Thursday     = 2010-01-11 [2008-11-06]\n",
      "× 2020 June 19 Friday           = 2010-01-11 [2020-06-19]\n",
      "× 2040 September 05 Wednesday   = 2010-01-11 [2040-09-05]\n",
      "[5] Corrects 0 / 3\tloss: 0.9871804714202881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:25<00:00, 15.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2021 March 06 Saturday        = 2010-01-11 [2021-03-06]\n",
      "× 1998 February 10 Tuesday      = 2010-01-11 [1998-02-10]\n",
      "× 2003 January 07 Tuesday       = 2010-01-11 [2003-01-07]\n",
      "[6] Corrects 0 / 3\tloss: 0.9825921654701233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2045 May 24 Wednesday         = 2000-01-11 [2045-05-24]\n",
      "× 2004 December 17 Friday       = 2000-01-11 [2004-12-17]\n",
      "× 2035 November 17 Saturday     = 2000-01-11 [2035-11-17]\n",
      "[7] Corrects 0 / 3\tloss: 0.9801673889160156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2019 December 31 Tuesday      = 2010-01-11 [2019-12-31]\n",
      "× 2000 September 23 Saturday    = 2010-01-11 [2000-09-23]\n",
      "× 2006 January 30 Monday        = 2010-01-11 [2006-01-30]\n",
      "[8] Corrects 0 / 3\tloss: 0.9780271649360657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2000 April 13 Thursday        = 2000-01-11 [2000-04-13]\n",
      "× 2042 February 25 Tuesday      = 2000-01-11 [2042-02-25]\n",
      "× 2039 July 13 Wednesday        = 2000-01-11 [2039-07-13]\n",
      "[9] Corrects 0 / 3\tloss: 0.9763128757476807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2020 February 19 Wednesday    = 2010-01-11 [2020-02-19]\n",
      "× 2020 July 04 Saturday         = 2000-01-11 [2020-07-04]\n",
      "× 2018 December 19 Wednesday    = 2010-01-11 [2018-12-19]\n",
      "[10] Corrects 0 / 3\tloss: 0.9734077453613281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2009 September 14 Monday      = 2000-01-11 [2009-09-14]\n",
      "× 1999 May 29 Saturday          = 2000-01-11 [1999-05-29]\n",
      "× 2022 December 30 Friday       = 2000-01-11 [2022-12-30]\n",
      "[11] Corrects 0 / 3\tloss: 0.9652674198150635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2023 January 31 Tuesday       = 2000-01-21 [2023-01-31]\n",
      "× 2026 June 03 Wednesday        = 2000-01-21 [2026-06-03]\n",
      "× 2021 June 29 Tuesday          = 2000-01-21 [2021-06-29]\n",
      "[12] Corrects 0 / 3\tloss: 0.959685742855072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2040 November 25 Sunday       = 2010-01-11 [2040-11-25]\n",
      "× 2017 November 07 Tuesday      = 2010-01-11 [2017-11-07]\n",
      "× 2045 May 12 Friday            = 2010-08-11 [2045-05-12]\n",
      "[13] Corrects 0 / 3\tloss: 0.9518120288848877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2030 November 15 Friday       = 2000-01-21 [2030-11-15]\n",
      "× 2000 January 25 Tuesday       = 2000-01-21 [2000-01-25]\n",
      "× 2021 July 24 Saturday         = 2010-08-11 [2021-07-24]\n",
      "[14] Corrects 0 / 3\tloss: 0.9403224587440491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2038 July 27 Tuesday          = 2000-07-11 [2038-07-27]\n",
      "× 2030 December 29 Sunday       = 2000-01-11 [2030-12-29]\n",
      "× 1997 October 16 Thursday      = 2010-01-11 [1997-10-16]\n",
      "[15] Corrects 0 / 3\tloss: 0.9332176446914673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2010 May 12 Wednesday         = 2010-07-11 [2010-05-12]\n",
      "× 2043 April 15 Wednesday       = 2010-09-11 [2043-04-15]\n",
      "× 2006 August 31 Thursday       = 2010-01-21 [2006-08-31]\n",
      "[16] Corrects 0 / 3\tloss: 0.9233273863792419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2037 February 14 Saturday     = 2010-01-21 [2037-02-14]\n",
      "× 2017 December 29 Friday       = 2010-01-23 [2017-12-29]\n",
      "× 2039 November 15 Tuesday      = 2010-01-13 [2039-11-15]\n",
      "[17] Corrects 0 / 3\tloss: 0.9066560864448547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:25<00:00, 15.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2008 October 02 Thursday      = 2010-01-11 [2008-10-02]\n",
      "× 2047 December 26 Thursday     = 2010-01-19 [2047-12-26]\n",
      "× 2045 August 02 Wednesday      = 2010-09-11 [2045-08-02]\n",
      "[18] Corrects 0 / 3\tloss: 0.8939329385757446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:25<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2030 September 14 Saturday    = 2010-09-10 [2030-09-14]\n",
      "× 2003 September 07 Sunday      = 2010-09-29 [2003-09-07]\n",
      "× 2051 March 21 Tuesday         = 2010-05-11 [2051-03-21]\n",
      "[19] Corrects 0 / 3\tloss: 0.8844974040985107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2017 May 30 Tuesday           = 2010-05-16 [2017-05-30]\n",
      "× 2008 November 05 Wednesday    = 2010-01-29 [2008-11-05]\n",
      "× 2018 August 28 Tuesday        = 2010-07-17 [2018-08-28]\n",
      "[20] Corrects 0 / 3\tloss: 0.8778515458106995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2012 August 18 Saturday       = 2010-09-13 [2012-08-18]\n",
      "× 1998 August 04 Tuesday        = 2010-07-10 [1998-08-04]\n",
      "× 2026 September 17 Thursday    = 2010-09-19 [2026-09-17]\n",
      "[21] Corrects 0 / 3\tloss: 0.8617922067642212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2012 September 26 Wednesday   = 2019-09-10 [2012-09-26]\n",
      "× 2030 April 19 Friday          = 2019-05-17 [2030-04-19]\n",
      "× 2036 February 12 Tuesday      = 2019-01-11 [2036-02-12]\n",
      "[22] Corrects 0 / 3\tloss: 0.8968986868858337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2008 June 28 Saturday         = 2000-05-19 [2008-06-28]\n",
      "× 2051 May 12 Friday            = 2010-05-11 [2051-05-12]\n",
      "× 2027 October 20 Wednesday     = 2010-01-11 [2027-10-20]\n",
      "[23] Corrects 0 / 3\tloss: 0.8729116320610046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2002 September 28 Saturday    = 2000-09-29 [2002-09-28]\n",
      "× 2002 August 20 Tuesday        = 2000-08-20 [2002-08-20]\n",
      "× 2023 April 10 Monday          = 2000-05-23 [2023-04-10]\n",
      "[24] Corrects 0 / 3\tloss: 0.8607420325279236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 1997 January 19 Sunday        = 2000-01-17 [1997-01-19]\n",
      "× 2036 May 06 Tuesday           = 2000-05-06 [2036-05-06]\n",
      "× 2040 May 29 Tuesday           = 2000-05-07 [2040-05-29]\n",
      "[25] Corrects 0 / 3\tloss: 0.8527868390083313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2002 August 30 Friday         = 2010-05-28 [2002-08-30]\n",
      "× 2003 April 14 Monday          = 2010-05-28 [2003-04-14]\n",
      "× 2040 June 04 Monday           = 2019-05-26 [2040-06-04]\n",
      "[26] Corrects 0 / 3\tloss: 0.8783330917358398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2022 May 10 Tuesday           = 2010-05-10 [2022-05-10]\n",
      "× 2014 August 02 Saturday       = 2010-08-11 [2014-08-02]\n",
      "× 2025 May 28 Wednesday         = 2010-03-19 [2025-05-28]\n",
      "[27] Corrects 0 / 3\tloss: 0.8575801849365234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2019 October 03 Thursday      = 2010-01-13 [2019-10-03]\n",
      "× 2005 July 26 Tuesday          = 2000-05-20 [2005-07-26]\n",
      "× 2036 October 12 Sunday        = 2010-01-11 [2036-10-12]\n",
      "[28] Corrects 0 / 3\tloss: 0.8388051986694336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:25<00:00, 15.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2028 October 28 Saturday      = 2020-11-28 [2028-10-28]\n",
      "× 2037 December 09 Wednesday    = 2020-11-28 [2037-12-09]\n",
      "× 2001 January 23 Tuesday       = 2040-01-13 [2001-01-23]\n",
      "[29] Corrects 0 / 3\tloss: 0.8256712555885315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2016 September 21 Wednesday   = 2011-09-11 [2016-09-21]\n",
      "× 2008 July 16 Wednesday        = 2000-08-20 [2008-07-16]\n",
      "× 2017 May 06 Saturday          = 2011-05-20 [2017-05-06]\n",
      "[30] Corrects 0 / 3\tloss: 0.8010959625244141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2004 July 04 Sunday           = 2030-05-03 [2004-07-04]\n",
      "× 2040 March 26 Monday          = 2041-05-13 [2040-03-26]\n",
      "× 2017 May 24 Wednesday         = 2011-08-10 [2017-05-24]\n",
      "[31] Corrects 0 / 3\tloss: 0.7629983425140381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2044 May 11 Wednesday         = 2041-05-11 [2044-05-11]\n",
      "× 2050 June 06 Monday           = 2000-05-00 [2050-06-06]\n",
      "× 2010 August 02 Monday         = 2041-03-01 [2010-08-02]\n",
      "[32] Corrects 0 / 3\tloss: 0.7417186498641968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2049 January 07 Thursday      = 2049-02-07 [2049-01-07]\n",
      "× 2007 February 25 Sunday       = 2000-11-03 [2007-02-25]\n",
      "× 2046 September 20 Thursday    = 2016-09-10 [2046-09-20]\n",
      "[33] Corrects 0 / 3\tloss: 0.7227723598480225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 1999 August 06 Friday         = 2998-08-03 [1999-08-06]\n",
      "× 2002 March 09 Saturday        = 2000-08-03 [2002-03-09]\n",
      "× 2044 September 10 Saturday    = 2048-09-10 [2044-09-10]\n",
      "[34] Corrects 0 / 3\tloss: 0.7039678692817688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2012 March 05 Monday          = 2012-05-03 [2012-03-05]\n",
      "× 2013 May 10 Friday            = 2013-05-11 [2013-05-10]\n",
      "× 2032 May 13 Thursday          = 2000-05-13 [2032-05-13]\n",
      "[35] Corrects 0 / 3\tloss: 0.6662900447845459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2008 January 12 Saturday      = 2000-11-01 [2008-01-12]\n",
      "○ 2026 August 17 Monday         = 2026-08-17 [2026-08-17]\n",
      "× 2049 December 29 Wednesday    = 2045-11-13 [2049-12-29]\n",
      "[36] Corrects 1 / 3\tloss: 0.6506381630897522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2034 July 05 Wednesday        = 2036-08-07 [2034-07-05]\n",
      "× 2047 July 14 Sunday           = 2047-05-10 [2047-07-14]\n",
      "× 2044 February 05 Friday       = 2049-02-03 [2044-02-05]\n",
      "[37] Corrects 0 / 3\tloss: 0.6395039558410645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2038 May 24 Monday            = 2030-05-10 [2038-05-24]\n",
      "× 2040 June 10 Sunday           = 2041-05-11 [2040-06-10]\n",
      "× 2025 April 06 Sunday          = 2020-05-01 [2025-04-06]\n",
      "[38] Corrects 0 / 3\tloss: 0.625211775302887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2016 September 30 Friday      = 2017-09-00 [2016-09-30]\n",
      "× 2004 March 28 Sunday          = 2034-05-23 [2004-03-28]\n",
      "× 2042 April 19 Saturday        = 2041-08-13 [2042-04-19]\n",
      "[39] Corrects 0 / 3\tloss: 0.6031246185302734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2020 June 01 Monday           = 2020-05-01 [2020-06-01]\n",
      "× 1999 September 30 Thursday    = 2999-09-09 [1999-09-30]\n",
      "× 2044 March 13 Sunday          = 2049-05-13 [2044-03-13]\n",
      "[40] Corrects 0 / 3\tloss: 0.5975330471992493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2041 January 19 Saturday      = 2041-01-29 [2041-01-19]\n",
      "× 2035 May 14 Monday            = 2030-05-11 [2035-05-14]\n",
      "× 2028 August 01 Tuesday        = 2020-08-02 [2028-08-01]\n",
      "[41] Corrects 0 / 3\tloss: 0.5851200222969055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2031 December 20 Saturday     = 2031-11-20 [2031-12-20]\n",
      "× 2002 June 12 Wednesday        = 2022-08-11 [2002-06-12]\n",
      "× 2014 November 20 Thursday     = 2016-11-21 [2014-11-20]\n",
      "[42] Corrects 0 / 3\tloss: 0.58054119348526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2035 December 30 Sunday       = 2035-11-01 [2035-12-30]\n",
      "× 2017 May 19 Friday            = 2017-05-13 [2017-05-19]\n",
      "× 2003 April 29 Tuesday         = 2003-03-13 [2003-04-29]\n",
      "[43] Corrects 0 / 3\tloss: 0.5413612127304077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2024 December 29 Sunday       = 2026-11-23 [2024-12-29]\n",
      "× 1999 May 25 Tuesday           = 2998-05-25 [1999-05-25]\n",
      "× 2023 September 04 Monday      = 2023-09-00 [2023-09-04]\n",
      "[44] Corrects 0 / 3\tloss: 0.5196526050567627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "○ 2040 October 05 Friday        = 2040-10-05 [2040-10-05]\n",
      "× 2030 July 09 Tuesday          = 2030-05-09 [2030-07-09]\n",
      "× 2014 February 11 Tuesday      = 2014-01-11 [2014-02-11]\n",
      "[45] Corrects 1 / 3\tloss: 0.5346515774726868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2024 October 28 Monday        = 2026-10-25 [2024-10-28]\n",
      "× 2051 January 29 Sunday        = 2041-02-23 [2051-01-29]\n",
      "× 2042 June 08 Sunday           = 2042-05-08 [2042-06-08]\n",
      "[46] Corrects 0 / 3\tloss: 0.5077794790267944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 1998 January 13 Tuesday       = 2997-01-13 [1998-01-13]\n",
      "× 2046 August 31 Friday         = 2047-08-02 [2046-08-31]\n",
      "× 2003 December 19 Friday       = 2000-11-18 [2003-12-19]\n",
      "[47] Corrects 0 / 3\tloss: 0.49513480067253113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "○ 2020 November 08 Sunday       = 2020-11-08 [2020-11-08]\n",
      "× 2013 July 28 Sunday           = 2013-05-28 [2013-07-28]\n",
      "○ 2004 May 29 Saturday          = 2004-05-29 [2004-05-29]\n",
      "[48] Corrects 2 / 3\tloss: 0.4780913293361664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2034 June 10 Saturday         = 2034-07-16 [2034-06-10]\n",
      "× 2028 February 04 Friday       = 2028-02-02 [2028-02-04]\n",
      "× 2005 April 18 Monday          = 2005-05-13 [2005-04-18]\n",
      "[49] Corrects 0 / 3\tloss: 0.5183485150337219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2027 June 08 Tuesday          = 2025-05-03 [2027-06-08]\n",
      "× 2019 April 08 Monday          = 2015-05-03 [2019-04-08]\n",
      "× 2041 February 19 Tuesday      = 2041-01-17 [2041-02-19]\n",
      "[50] Corrects 0 / 3\tloss: 0.4579779803752899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2030 September 12 Thursday    = 2033-09-21 [2030-09-12]\n",
      "× 2037 December 08 Tuesday      = 2037-11-08 [2037-12-08]\n",
      "× 2045 January 18 Wednesday     = 2049-01-25 [2045-01-18]\n",
      "[51] Corrects 0 / 3\tloss: 0.5969424843788147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2014 September 16 Tuesday     = 2014-09-11 [2014-09-16]\n",
      "× 2016 April 05 Tuesday         = 2016-03-03 [2016-04-05]\n",
      "× 2018 November 14 Wednesday    = 2013-11-11 [2018-11-14]\n",
      "[52] Corrects 0 / 3\tloss: 0.440512478351593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "○ 2047 November 15 Friday       = 2047-11-15 [2047-11-15]\n",
      "× 2049 September 03 Friday      = 2049-09-09 [2049-09-03]\n",
      "× 2015 November 20 Friday       = 2015-11-21 [2015-11-20]\n",
      "[53] Corrects 1 / 3\tloss: 0.43639615178108215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2039 April 09 Saturday        = 2039-08-03 [2039-04-09]\n",
      "○ 2019 August 23 Friday         = 2019-08-23 [2019-08-23]\n",
      "○ 2008 October 01 Wednesday     = 2008-10-01 [2008-10-01]\n",
      "[54] Corrects 2 / 3\tloss: 0.43062877655029297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 1998 January 26 Monday        = 2994-01-21 [1998-01-26]\n",
      "× 2008 July 19 Saturday         = 2003-04-19 [2008-07-19]\n",
      "× 2050 October 21 Friday        = 2030-10-21 [2050-10-21]\n",
      "[55] Corrects 0 / 3\tloss: 0.4523870348930359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2040 May 28 Monday            = 2040-05-23 [2040-05-28]\n",
      "× 2005 April 06 Wednesday       = 2005-08-06 [2005-04-06]\n",
      "× 2006 March 20 Monday          = 2006-05-21 [2006-03-20]\n",
      "[56] Corrects 0 / 3\tloss: 0.4233287572860718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2002 March 26 Tuesday         = 2002-03-21 [2002-03-26]\n",
      "× 2035 January 05 Friday        = 2035-02-05 [2035-01-05]\n",
      "× 2032 March 05 Friday          = 2032-05-03 [2032-03-05]\n",
      "[57] Corrects 0 / 3\tloss: 0.42764517664909363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "○ 2005 November 28 Monday       = 2005-11-28 [2005-11-28]\n",
      "× 2015 August 12 Wednesday      = 2015-08-11 [2015-08-12]\n",
      "× 2030 December 16 Monday       = 2030-11-16 [2030-12-16]\n",
      "[58] Corrects 1 / 3\tloss: 0.417190819978714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2037 July 28 Tuesday          = 2037-05-23 [2037-07-28]\n",
      "× 2009 July 12 Sunday           = 2009-05-11 [2009-07-12]\n",
      "× 2006 March 05 Sunday          = 2006-05-03 [2006-03-05]\n",
      "[59] Corrects 0 / 3\tloss: 0.4126042425632477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2023 November 20 Monday       = 2023-11-21 [2023-11-20]\n",
      "× 2001 August 29 Wednesday      = 2001-08-17 [2001-08-29]\n",
      "× 2036 April 27 Sunday          = 2036-05-23 [2036-04-27]\n",
      "[60] Corrects 0 / 3\tloss: 0.4110763669013977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2046 June 19 Tuesday          = 2046-05-17 [2046-06-19]\n",
      "× 2006 August 08 Tuesday        = 2006-08-03 [2006-08-08]\n",
      "○ 2009 May 26 Tuesday           = 2009-05-26 [2009-05-26]\n",
      "[61] Corrects 1 / 3\tloss: 0.4148584306240082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2002 June 21 Friday           = 2002-05-21 [2002-06-21]\n",
      "○ 2021 November 13 Saturday     = 2021-11-13 [2021-11-13]\n",
      "× 2017 July 17 Monday           = 2017-05-17 [2017-07-17]\n",
      "[62] Corrects 1 / 3\tloss: 0.42626798152923584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "○ 2014 February 03 Monday       = 2014-02-03 [2014-02-03]\n",
      "× 2002 January 28 Monday        = 2002-02-25 [2002-01-28]\n",
      "× 2025 April 04 Friday          = 2025-05-03 [2025-04-04]\n",
      "[63] Corrects 1 / 3\tloss: 0.40202319622039795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2033 November 05 Saturday     = 2033-12-09 [2033-11-05]\n",
      "× 2014 May 04 Sunday            = 2014-05-01 [2014-05-04]\n",
      "○ 2044 May 23 Monday            = 2044-05-23 [2044-05-23]\n",
      "[64] Corrects 1 / 3\tloss: 0.3910188674926758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2027 January 19 Tuesday       = 2029-02-13 [2027-01-19]\n",
      "× 2039 February 15 Tuesday      = 2039-01-15 [2039-02-15]\n",
      "× 2027 December 30 Thursday     = 2029-12-02 [2027-12-30]\n",
      "[65] Corrects 0 / 3\tloss: 0.4035559892654419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2038 September 09 Thursday    = 2033-09-09 [2038-09-09]\n",
      "○ 2042 October 23 Thursday      = 2042-10-23 [2042-10-23]\n",
      "○ 2019 September 20 Friday      = 2019-09-20 [2019-09-20]\n",
      "[66] Corrects 2 / 3\tloss: 0.3964485824108124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2033 September 03 Saturday    = 2033-09-09 [2033-09-03]\n",
      "○ 2037 February 06 Friday       = 2037-02-06 [2037-02-06]\n",
      "× 2001 January 27 Saturday      = 2001-02-27 [2001-01-27]\n",
      "[67] Corrects 1 / 3\tloss: 0.3832419514656067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2034 August 31 Thursday       = 2034-08-02 [2034-08-31]\n",
      "× 2003 December 30 Tuesday      = 2003-12-02 [2003-12-30]\n",
      "○ 2046 December 03 Monday       = 2046-12-03 [2046-12-03]\n",
      "[68] Corrects 1 / 3\tloss: 0.37681806087493896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2024 July 01 Monday           = 2024-05-02 [2024-07-01]\n",
      "× 2037 September 18 Friday      = 2037-09-19 [2037-09-18]\n",
      "○ 2016 February 25 Thursday     = 2016-02-25 [2016-02-25]\n",
      "[69] Corrects 1 / 3\tloss: 0.38226595520973206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2000 December 22 Friday       = 2000-11-21 [2000-12-22]\n",
      "× 2044 June 23 Thursday         = 2044-08-23 [2044-06-23]\n",
      "○ 2008 May 09 Friday            = 2008-05-09 [2008-05-09]\n",
      "[70] Corrects 1 / 3\tloss: 0.37889155745506287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2001 March 09 Friday          = 2001-03-03 [2001-03-09]\n",
      "× 2022 November 27 Sunday       = 2022-12-28 [2022-11-27]\n",
      "× 2037 August 31 Monday         = 2037-08-02 [2037-08-31]\n",
      "[71] Corrects 0 / 3\tloss: 0.36796581745147705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:26<00:00, 14.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2032 July 02 Friday           = 2032-05-02 [2032-07-02]\n",
      "× 2026 October 30 Friday        = 2026-10-02 [2026-10-30]\n",
      "× 2035 September 22 Saturday    = 2035-09-21 [2035-09-22]\n",
      "[72] Corrects 0 / 3\tloss: 0.3574833571910858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2004 June 03 Thursday         = 2004-08-03 [2004-06-03]\n",
      "× 2029 October 30 Tuesday       = 2029-02-11 [2029-10-30]\n",
      "× 2011 May 11 Wednesday         = 2011-08-12 [2011-05-11]\n",
      "[73] Corrects 0 / 3\tloss: 0.36366480588912964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2021 June 25 Friday           = 2021-05-25 [2021-06-25]\n",
      "× 2014 August 10 Sunday         = 2014-08-21 [2014-08-10]\n",
      "○ 2020 December 15 Tuesday      = 2020-12-15 [2020-12-15]\n",
      "[74] Corrects 1 / 3\tloss: 0.37249624729156494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2050 April 20 Wednesday       = 2030-08-20 [2050-04-20]\n",
      "○ 2014 August 01 Friday         = 2014-08-01 [2014-08-01]\n",
      "× 2026 January 01 Thursday      = 2026-02-02 [2026-01-01]\n",
      "[75] Corrects 1 / 3\tloss: 0.39648592472076416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2040 April 30 Monday          = 2040-03-06 [2040-04-30]\n",
      "× 2015 August 27 Thursday       = 2015-08-23 [2015-08-27]\n",
      "× 2037 February 15 Sunday       = 2037-01-18 [2037-02-15]\n",
      "[76] Corrects 0 / 3\tloss: 0.35802480578422546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "○ 2014 March 07 Friday          = 2014-03-07 [2014-03-07]\n",
      "○ 2037 July 10 Friday           = 2037-07-10 [2037-07-10]\n",
      "○ 2000 September 29 Friday      = 2000-09-29 [2000-09-29]\n",
      "[77] Corrects 3 / 3\tloss: 0.35307151079177856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "× 2047 October 17 Thursday      = 2047-10-10 [2047-10-17]\n",
      "× 2022 November 01 Tuesday      = 2022-12-02 [2022-11-01]\n",
      "○ 2008 August 08 Friday         = 2008-08-08 [2008-08-08]\n",
      "[78] Corrects 1 / 3\tloss: 0.34365135431289673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 390/390 [00:27<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "○ 2017 February 08 Wednesday    = 2017-02-08 [2017-02-08]\n",
      "× 2034 August 14 Monday         = 2034-08-16 [2034-08-14]\n",
      "× 1997 December 09 Tuesday      = 1997-12-08 [1997-12-09]\n",
      "[79] Corrects 1 / 3\tloss: 0.3405943512916565\n",
      "Saved: network.state.pkl\n",
      "× 1998 June 28 Sunday           = 1998-05-23 [1998-06-28]\n",
      "○ 2041 May 05 Sunday            = 2041-05-05 [2041-05-05]\n",
      "× 2001 November 22 Thursday     = 2001-12-21 [2001-11-22]\n",
      "○ 2034 December 04 Monday       = 2034-12-04 [2034-12-04]\n",
      "○ 2021 July 23 Friday           = 2021-07-23 [2021-07-23]\n",
      "○ 2027 October 21 Thursday      = 2027-10-21 [2027-10-21]\n",
      "○ 2045 March 17 Friday          = 2045-03-17 [2045-03-17]\n",
      "× 2012 June 10 Sunday           = 2012-05-10 [2012-06-10]\n",
      "× 2048 April 30 Thursday        = 2048-08-04 [2048-04-30]\n",
      "× 2047 December 03 Tuesday      = 2047-11-03 [2047-12-03]\n",
      "× 2023 November 20 Monday       = 2023-12-20 [2023-11-20]\n",
      "× 2010 May 26 Wednesday         = 2010-03-21 [2010-05-26]\n",
      "× 2017 July 30 Sunday           = 2017-05-05 [2017-07-30]\n",
      "○ 2045 May 28 Sunday            = 2045-05-28 [2045-05-28]\n",
      "× 2027 September 27 Monday      = 2027-09-29 [2027-09-27]\n",
      "× 2036 May 13 Tuesday           = 2036-07-13 [2036-05-13]\n",
      "× 1998 October 02 Friday        = 1998-10-01 [1998-10-02]\n",
      "× 2022 January 27 Thursday      = 2022-02-23 [2022-01-27]\n",
      "× 2036 March 16 Sunday          = 2036-07-12 [2036-03-16]\n",
      "× 2049 December 14 Tuesday      = 2049-11-14 [2049-12-14]\n",
      "× 2007 February 04 Sunday       = 2007-02-06 [2007-02-04]\n",
      "× 2029 November 22 Thursday     = 2029-12-21 [2029-11-22]\n",
      "× 2014 December 18 Thursday     = 2014-11-18 [2014-12-18]\n",
      "× 2020 September 22 Tuesday     = 2020-09-21 [2020-09-22]\n",
      "× 2002 June 09 Sunday           = 2002-05-09 [2002-06-09]\n",
      "× 2031 December 11 Thursday     = 2031-11-11 [2031-12-11]\n",
      "× 2002 February 01 Friday       = 2002-02-02 [2002-02-01]\n",
      "× 2016 December 29 Thursday     = 2016-11-29 [2016-12-29]\n",
      "× 2016 June 22 Wednesday        = 2016-04-21 [2016-06-22]\n",
      "× 1997 March 13 Thursday        = 1997-08-13 [1997-03-13]\n",
      "× 2037 October 30 Friday        = 2037-10-02 [2037-10-30]\n",
      "× 2008 October 27 Monday        = 2008-10-25 [2008-10-27]\n",
      "× 2011 April 19 Tuesday         = 2011-04-13 [2011-04-19]\n",
      "× 2007 November 30 Friday       = 2007-12-01 [2007-11-30]\n",
      "○ 2040 August 23 Thursday       = 2040-08-23 [2040-08-23]\n",
      "× 2006 April 18 Tuesday         = 2006-04-13 [2006-04-18]\n",
      "× 2029 January 08 Monday        = 2029-02-07 [2029-01-08]\n",
      "× 2035 October 06 Saturday      = 2035-10-01 [2035-10-06]\n",
      "○ 2017 November 18 Saturday     = 2017-11-18 [2017-11-18]\n",
      "× 2010 June 13 Sunday           = 2010-07-13 [2010-06-13]\n",
      "○ 2002 May 07 Tuesday           = 2002-05-07 [2002-05-07]\n",
      "× 2013 June 12 Wednesday        = 2013-04-12 [2013-06-12]\n",
      "× 2046 May 29 Tuesday           = 2046-07-23 [2046-05-29]\n",
      "× 2020 August 11 Tuesday        = 2020-04-11 [2020-08-11]\n",
      "○ 2036 December 20 Saturday     = 2036-12-20 [2036-12-20]\n",
      "○ 2012 October 29 Monday        = 2012-10-29 [2012-10-29]\n",
      "○ 2024 October 17 Thursday      = 2024-10-17 [2024-10-17]\n",
      "○ 2037 April 21 Tuesday         = 2037-04-21 [2037-04-21]\n",
      "○ 2000 February 23 Wednesday    = 2000-02-23 [2000-02-23]\n",
      "× 2029 April 11 Wednesday       = 2029-08-11 [2029-04-11]\n",
      "× 2031 April 25 Friday          = 2031-03-23 [2031-04-25]\n",
      "○ 2017 May 05 Friday            = 2017-05-05 [2017-05-05]\n",
      "× 2014 March 24 Monday          = 2014-03-21 [2014-03-24]\n",
      "× 2007 March 11 Sunday          = 2007-07-11 [2007-03-11]\n",
      "× 2014 December 09 Tuesday      = 2014-12-08 [2014-12-09]\n",
      "× 2030 June 23 Sunday           = 2030-07-23 [2030-06-23]\n",
      "× 2023 January 22 Sunday        = 2023-02-21 [2023-01-22]\n",
      "○ 2007 April 10 Tuesday         = 2007-04-10 [2007-04-10]\n",
      "× 2010 March 10 Wednesday       = 2010-08-10 [2010-03-10]\n",
      "○ 2019 October 17 Thursday      = 2019-10-17 [2019-10-17]\n",
      "○ 2012 December 25 Tuesday      = 2012-12-25 [2012-12-25]\n",
      "○ 2018 November 13 Tuesday      = 2018-11-13 [2018-11-13]\n",
      "○ 2000 December 08 Friday       = 2000-12-08 [2000-12-08]\n",
      "× 2015 November 05 Thursday     = 2015-12-05 [2015-11-05]\n",
      "× 2009 December 27 Sunday       = 2009-12-28 [2009-12-27]\n",
      "× 2046 June 19 Tuesday          = 2046-07-13 [2046-06-19]\n",
      "× 1998 February 03 Tuesday      = 1998-01-03 [1998-02-03]\n",
      "× 1996 December 04 Wednesday    = 1997-12-01 [1996-12-04]\n",
      "× 2029 January 23 Tuesday       = 2029-02-23 [2029-01-23]\n",
      "× 2044 April 09 Saturday        = 2044-08-07 [2044-04-09]\n",
      "× 2050 September 14 Wednesday   = 2030-09-12 [2050-09-14]\n",
      "× 2019 July 16 Tuesday          = 2019-05-11 [2019-07-16]\n",
      "○ 2040 November 18 Sunday       = 2040-11-18 [2040-11-18]\n",
      "× 2003 September 24 Wednesday   = 2003-09-29 [2003-09-24]\n",
      "× 2033 December 30 Friday       = 2033-12-02 [2033-12-30]\n",
      "○ 2043 February 07 Saturday     = 2043-02-07 [2043-02-07]\n",
      "× 2027 November 29 Monday       = 2027-12-23 [2027-11-29]\n",
      "○ 2046 February 08 Thursday     = 2046-02-08 [2046-02-08]\n",
      "× 2003 November 09 Sunday       = 2003-12-07 [2003-11-09]\n",
      "○ 1997 May 06 Tuesday           = 1997-05-06 [1997-05-06]\n",
      "× 2025 July 28 Monday           = 2025-05-23 [2025-07-28]\n",
      "× 2014 July 24 Thursday         = 2014-04-26 [2014-07-24]\n",
      "× 1997 March 18 Tuesday         = 1997-04-18 [1997-03-18]\n",
      "× 2032 January 15 Thursday      = 2032-02-15 [2032-01-15]\n",
      "× 2016 October 06 Thursday      = 2016-10-01 [2016-10-06]\n",
      "× 2047 August 19 Monday         = 2047-08-13 [2047-08-19]\n",
      "○ 2050 March 04 Friday          = 2050-03-04 [2050-03-04]\n",
      "× 2006 May 04 Thursday          = 2006-03-04 [2006-05-04]\n",
      "○ 2036 October 10 Friday        = 2036-10-10 [2036-10-10]\n",
      "× 1998 September 28 Monday      = 1998-09-29 [1998-09-28]\n",
      "○ 2011 February 07 Monday       = 2011-02-07 [2011-02-07]\n",
      "○ 2010 August 19 Thursday       = 2010-08-19 [2010-08-19]\n",
      "○ 2004 October 01 Friday        = 2004-10-01 [2004-10-01]\n",
      "○ 2029 May 13 Sunday            = 2029-05-13 [2029-05-13]\n",
      "× 1998 February 22 Sunday       = 1998-01-21 [1998-02-22]\n",
      "× 2041 January 24 Thursday      = 2041-01-26 [2041-01-24]\n",
      "× 2033 May 04 Wednesday         = 2033-03-06 [2033-05-04]\n",
      "○ 2023 October 20 Friday        = 2023-10-20 [2023-10-20]\n",
      "○ 2010 September 29 Wednesday   = 2010-09-29 [2010-09-29]\n",
      "× 2046 January 31 Wednesday     = 2046-02-01 [2046-01-31]\n",
      "Score: 32 / 100\tAccuracy: 0.32\n",
      "Saved: temp.state.pkl\n",
      "Change to cpu.\n",
      "Loaded: temp.state.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                       | 1/50000 [00:00<2:04:01,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: figure.png\n",
      "Change to gpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "program = Program3()\n",
    "if __name__ == '__main__':\n",
    "    program()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1280x960 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "plt.plot(program.losses, label='loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "img = Image.open('figure.png')\n",
    "fig = plt.figure(dpi=200)\n",
    "ax = fig.add_subplot(1, 1, 1) # (row, col, num)\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
